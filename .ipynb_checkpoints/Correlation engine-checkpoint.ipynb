{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "items = []\n",
    "items.append(\"I am mighty #annoyed today #food\")\n",
    "items.append(\"I am #annoyed at this #software\")\n",
    "items.append(\"#software makes me #annoyed\")\n",
    "items.append(\"#food makes me #happy and #hungry\")\n",
    "items.append(\"#food again #happy\")\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "def allequal(data):\n",
    "    equality = data[0]\n",
    "    for item in data:\n",
    "        if item != equality:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def correlate_hashags(items):\n",
    "    keys = set([])\n",
    "    presences = []\n",
    "    for item in items:\n",
    "        match = re.findall(\"#([A-Za-z0-9]*)\", item)\n",
    "        this_presences = {}\n",
    "        for matched_item in match:\n",
    "            this_presences[matched_item] = True\n",
    "            keys.add(matched_item)\n",
    "        presences.append(this_presences)\n",
    "    \n",
    "    run_correlation = True\n",
    "    for key, subkey in combinations(keys, 2):\n",
    "            data1 = []\n",
    "            data2 = []\n",
    "            run_correlation = True\n",
    "            for i, post in enumerate(items):\n",
    "                data1.append(key in presences[i])\n",
    "                data2.append(subkey in presences[i])\n",
    "            if allequal(data1):\n",
    "                print(\"Correlation is constant, {} appears everywhere\".format(key))\n",
    "                run_correlation = False\n",
    "            if allequal(data2):\n",
    "                print(\"Correlation is constant, {} appears everywhere\".format(subkey))\n",
    "                run_correlation = False\n",
    "            if run_correlation:\n",
    "                corr, _ = pearsonr(data1, data2)\n",
    "                # print(\"Testing {} and {} {:03f}\".format(key, subkey, corr))\n",
    "                yield (key, subkey, corr)\n",
    "\n",
    "corrs = correlate_hashags(items)\n",
    "for key, subkey, corr in corrs:\n",
    "    if corr > 0:\n",
    "        print(\"{} has a positive correlation with {} @ {:.3f}\".format(key, subkey, corr))\n",
    "    else:\n",
    "        # print(\"{} has a negative correlation with {} @ {:.3f}\".format(key, subkey, corr))\n",
    "        print(\"You don't get {} with {}\".format(key, subkey, corr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "items = []\n",
    "items.append(\"2020-08-16 20:17 Another Innocuous log line\")\n",
    "items.append(\"2020-08-16 20:17 Log line that causes the error\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Innocuous log line\")\n",
    "items.append(\"2020-08-16 20:17 Log line that causes the error\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Log line that causes the error\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 A third innocuous log line\")\n",
    "items.append(\"2020-08-16 20:17 Log line that causes the error\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Log line that causes the error\")\n",
    "items.append(\"2020-08-16 20:17 Innocuous log line\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Another cause of error\")\n",
    "items.append(\"2020-08-16 20:17 Innocuous log line\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Another cause of error\")\n",
    "items.append(\"2020-08-16 20:17 Innocuous log line\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Another cause of error\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "items.append(\"2020-08-16 20:17 Another cause of error\")\n",
    "items.append(\"2020-08-16 20:17 ERROR: error caused\")\n",
    "\n",
    "def find_error_cause(items):\n",
    "    chances = {}\n",
    "    for scanback in range(0, 10):\n",
    "        for line in items:\n",
    "            if \"ERROR\" in line:\n",
    "                continue\n",
    "            errors = []\n",
    "            logs = []\n",
    "            log_line_identity = line.split(\" \")[2:]\n",
    "            log_line = \" \".join(log_line_identity)\n",
    "            for _ in range(0, scanback):\n",
    "                errors.append(0)\n",
    "\n",
    "            for line in items:\n",
    "                if \"ERROR\" in line:\n",
    "                    errors.append(100)\n",
    "                else:\n",
    "                    errors.append(0)\n",
    "\n",
    "            for line in items:\n",
    "                if log_line in line:\n",
    "                    logs.append(100)\n",
    "                else:\n",
    "                    logs.append(0)\n",
    "\n",
    "            for _ in range(0, scanback):\n",
    "                logs.append(0)\n",
    "\n",
    "            corr, _ = pearsonr(errors, logs)\n",
    "\n",
    "            if corr > 0:\n",
    "                chances[log_line] = chances.get(log_line, 0) + 1\n",
    "    return Counter(chances).most_common()\n",
    "\n",
    "            \n",
    "\n",
    "chances = find_error_cause(items)\n",
    "print(chances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit([\"hello how are you\", \"i am fine\"])\n",
    "X = cv.transform([\"hello how are you\", \"i am fine\"])\n",
    "X_test = cv.transform([\"how are you\"])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: 0 for word in cv.get_feature_names()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comment out the following line if you are using Jupyter Notebook\n",
    "# %matplotlib inline\n",
    "# Use a predefined style set\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Import Faker\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "# To ensure the results are reproducible\n",
    "Faker.seed(4321)\n",
    "\n",
    "names_list = []\n",
    "\n",
    "fake = Faker()\n",
    "for _ in range(100):\n",
    "  names_list.append(fake.name())\n",
    "\n",
    "# To ensure the results are reproducible\n",
    "np.random.seed(7)\n",
    "\n",
    "salaries = []\n",
    "for _ in range(100):\n",
    "    salary = np.random.randint(1000,2500)\n",
    "    salaries.append(salary)\n",
    "\n",
    "# Create pandas DataFrame\n",
    "salary_df = pd.DataFrame(\n",
    "    {'Person': names_list,\n",
    "     'Salary (in USD)': salaries\n",
    "    })\n",
    "\n",
    "# Print a subsection of the DataFrame\n",
    "print(salary_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.at[16, 'Salary (in USD)'] = 23\n",
    "salary_df.at[65, 'Salary (in USD)'] = 17\n",
    "\n",
    "# Verify if the salaries were changed\n",
    "print(salary_df.loc[16])\n",
    "print(salary_df.loc[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['Salary (in USD)'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_raw = salary_df['Salary (in USD)'].values\n",
    "\n",
    "# For compatibility with the SciPy implementation\n",
    "salary_raw = salary_raw.reshape(-1, 1)\n",
    "salary_raw = salary_raw.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans\n",
    "    \n",
    "# Specify the data and the number of clusters to kmeans()\n",
    "centroids, avg_distance = kmeans(salary_raw, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq\n",
    "groups, cdist = vq(salary_raw, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(salary_raw, np.arange(0,100), c=groups)\n",
    "plt.xlabel('Salaries in (USD)')\n",
    "plt.ylabel('Indices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salary_df['Salary (in USD)'].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "# Train kNN detector\n",
    "clf = KNN(contamination=0.02, n_neighbors=5)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.labels_ \n",
    "    \n",
    "# Outlier scores\n",
    "y_train_scores = clf.decision_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df['class'] = 0\n",
    "\n",
    "# Manually edit the labels for the anomalies\n",
    "salary_df.at[16, 'class'] = 1\n",
    "salary_df.at[65, 'class'] = 1\n",
    "y = salary_df['class'].values\n",
    "\n",
    "# Veirfy \n",
    "print(salary_df.loc[16])\n",
    "\n",
    "from pyod.utils import evaluate_print\n",
    "\n",
    "# Evaluate on the training data\n",
    "evaluate_print('KNN', y, y_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([[1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from numpy import array, pad, append\n",
    "class WordIdentifier():\n",
    "    def __init__(self):\n",
    "        self.words = {}\n",
    "    def fit(self, data):\n",
    "        lines = []\n",
    "        for line in data:\n",
    "            words = line.split(\" \")\n",
    "            line_ids = []\n",
    "            for word in words:\n",
    "                if word in self.words:\n",
    "                    word_id = self.words[word]\n",
    "                else:\n",
    "                    word_id = len(self.words.values())\n",
    "                    self.words[word] = word_id\n",
    "                \n",
    "          \n",
    "        \n",
    "    def test(self, data):\n",
    "        weirdness_score = 0\n",
    "        for line in data:\n",
    "            words = line.split(\" \")\n",
    "            for word in words:\n",
    "                if word not in self.words:\n",
    "                    weirdness_score = weirdness_score + 1\n",
    "                    \n",
    "        return weirdness_score\n",
    "\n",
    "cv = WordIdentifier()\n",
    "\n",
    "X = cv.fit([\"hello how are you\", \"i am fine\"])\n",
    "X_test = cv.test([\"this is a strange sentence\", \"another sentence here\"])\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Db():\n",
    "    def __init__(self):\n",
    "        self.partition_keys = []\n",
    "        self.db = {}\n",
    "        \n",
    "    def add_access_pattern(self, data):\n",
    "        from_table, operator, to_table = data.split(\" \")\n",
    "        if operator == \"-*->\":\n",
    "            self.partition_keys.append({\n",
    "                \"partition_key\": from_table,\n",
    "                \"sort_key\": to_table\n",
    "            })\n",
    "       \n",
    "        \n",
    "    def insert(self, field, data):\n",
    "        for partition_key in self.partition_keys:\n",
    "            if partition_key[\"partition_key\"].startswith(field):\n",
    "                subcollection = data[partition_key[\"sort_key\"]]\n",
    "                del data[partition_key[\"sort_key\"]]\n",
    "                parent_key = \"{}-{}\".format(partition_key[\"partition_key\"], data[\"id\"])\n",
    "                self.db[parent_key] = data\n",
    "                \n",
    "                for sub in subcollection:\n",
    "                    self.db[\"{}:{}-{}\".format(parent_key, partition_key[\"sort_key\"], sub[\"id\"])] = sub\n",
    "                \n",
    "db = Db()\n",
    "db.add_access_pattern(\"strategies -*-> problems\")\n",
    "db.insert(\"strategies\", {\"strategy\": \"strategy name\", \"id\": 1, \"problems\": [{\"problem_name\": \"problem name\", \"id\": 1}]})\n",
    "\n",
    "print(db.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def nonlin(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    "    'This word has document too'\n",
    "]\n",
    "test = corpus + [\"This is also first document\", \"This doesnt contain that word\"]\n",
    "\n",
    "size = len(test)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "test_vector = vectorizer.fit_transform(test).toarray()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "print(X.shape)\n",
    "                \n",
    "y = np.array([[1],\n",
    "\t\t\t[0],\n",
    "\t\t\t[0],\n",
    "\t\t\t[1],\n",
    "            [0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2*np.random.random((X.shape[1], X.shape[1])) - 1\n",
    "syn1 = 2*np.random.random((X.shape[1], X.shape[1])) - 1\n",
    "syn2 = 2*np.random.random((X.shape[1], X.shape[1])) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "\n",
    "\t# Feed forward through layers 0, 1, and 2\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    l2 = nonlin(np.dot(l1,syn1))\n",
    "    l3 = nonlin(np.dot(l2,syn2))\n",
    "\n",
    "    # how much did we miss the target value?\n",
    "    l3_error = y - l3\n",
    "    \n",
    "    if (j% 10_000) == 0:\n",
    "        # print(\"Error:\".format() + str(np.mean(np.abs(l3_error))))\n",
    "        pass # print(l3)\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l3_delta = l3_error * nonlin(l3,deriv=True)\n",
    "    l2_error = l3_delta.dot(syn2.T)\n",
    "    l2_delta = l2_error*nonlin(l2,deriv=True)\n",
    "\n",
    "    # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    \n",
    "    # in what direction is the target l1?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    syn2 += l2.T.dot(l3_delta)\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "\n",
    "l0 = X\n",
    "l1 = nonlin(np.dot(l0,syn0))\n",
    "l2 = nonlin(np.dot(l1,syn1))\n",
    "l3 = nonlin(np.dot(l2,syn2))\n",
    "print(\"Learned result:\")\n",
    "print(l3.round())\n",
    "    \n",
    "# Test weights\n",
    "\n",
    "X = test_vector\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "row = []\n",
    "col = []\n",
    "for _ in range(0, X.shape[1]):\n",
    "    row.append(1)\n",
    "\n",
    "\n",
    "for _ in range(X.shape[0], X.shape[1]):\n",
    "    X =  np.vstack([X, np.array(row)])\n",
    "print(\"X shape \", X.shape)\n",
    "l0 = X\n",
    "for _ in range(0, X.shape[1]):\n",
    "    col.append([1])\n",
    "row = []\n",
    "for _ in range(0, syn0.shape[1]):\n",
    "    row.append(1)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for _ in range(syn0.shape[0], X.shape[1]):\n",
    "    syn0 =  np.vstack([syn0, np.array(row)])\n",
    "for _ in range(syn1.shape[0], X.shape[1]):\n",
    "    syn1 =  np.vstack([syn1, np.array(row)])\n",
    "for _ in range(syn2.shape[0], X.shape[1]):\n",
    "    syn2 =  np.vstack([syn2, np.array(row)])\n",
    "\n",
    "for _ in range(syn0.shape[1], X.shape[1]):\n",
    "    syn0 = np.hstack([syn0, np.array(col)])\n",
    "    \n",
    "for _ in range(syn1.shape[1], X.shape[1]):\n",
    "    syn1 = np.hstack([syn1, np.array(col)])\n",
    "\n",
    "for _ in range(syn2.shape[1], X.shape[1]):\n",
    "    syn2 = np.hstack([syn2, np.array(col)])\n",
    "\n",
    "print(syn0.shape)\n",
    "\n",
    "l1 = nonlin(np.dot(l0,syn0))\n",
    "#l2 = nonlin(np.dot(l1,syn1))\n",
    "#l3 = nonlin(np.dot(l2,syn2))\n",
    "print(\"Learned result:\")\n",
    "print(l1.round())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*np.random.random((4,4)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "                \n",
    "y = np.array([[1],\n",
    "\t\t\t[0],\n",
    "\t\t\t[0],\n",
    "\t\t\t[1]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2*np.random.random((9,9)) - 1\n",
    "syn1 = 2*np.random.random((9,9)) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "\n",
    "\t# Feed forward through layers 0, 1, and 2\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    l2 = nonlin(np.dot(l1,syn1))\n",
    "\n",
    "    # how much did we miss the target value?\n",
    "    l2_error = y - l2\n",
    "    \n",
    "    if (j% 10000) == 0:\n",
    "        print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l2_delta = l2_error*nonlin(l2,deriv=True)\n",
    "\n",
    "    # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    # in what direction is the target l1?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "\n",
    "l0 = X\n",
    "l1 = nonlin(np.dot(l0,syn0))\n",
    "l2 = nonlin(np.dot(l1,syn1))\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self, value):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = value\n",
    "        \n",
    "    def insert(self, value):\n",
    "        if self.left == None \\\n",
    "            and value < self.value:\n",
    "                self.left = Tree(value)\n",
    "        elif self.right == None \\\n",
    "        and value > self.value:\n",
    "                self.right = Tree(value)\n",
    "                \n",
    "        elif value > self.value:\n",
    "            self.right.insert(value)\n",
    "        elif value < self.value:\n",
    "            self.left.insert(value)\n",
    "            \n",
    "    def walk(self):\n",
    "        if self.left:\n",
    "            self.left.walk()\n",
    "        print(self.value)\n",
    "        if self.right:\n",
    "            self.right.walk()\n",
    "            \n",
    "\n",
    "root = Tree(6)\n",
    "root.insert(4)\n",
    "root.insert(7)\n",
    "root.walk()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def insert(self, value):\n",
    "        if self.left == None and value <= self.value:\n",
    "            self.left = Tree(value)\n",
    "        elif self.right == None and value > self.value:\n",
    "            self.right = Tree(value)\n",
    "        elif value > self.value:\n",
    "            self.right.insert(value)\n",
    "        elif value < self.value:\n",
    "            self.left.insert(value)\n",
    "        elif self.value == \"\":\n",
    "            self.value = value\n",
    "        return self\n",
    "\n",
    "    def walk(self, less_than, stop):\n",
    "       \n",
    "        if self.left:\n",
    "            yield from self.left.walk(less_than, stop)\n",
    "        if less_than <= self.value and self.value <= stop:\n",
    "            yield self.value\n",
    "        if self.right:\n",
    "            yield from self.right.walk(less_than, stop)\n",
    "        \n",
    "\n",
    "root = Tree(\"\") \\\n",
    ".insert(\"2020-10-01\") \\\n",
    ".insert(\"2020-07-01\") \\\n",
    ".insert(\"2020-05-01\") \\\n",
    ".insert(\"2020-06-01\") \\\n",
    ".insert(\"2020-07-01\") \\\n",
    ".insert(\"2020-08-01\") \\\n",
    ".insert(\"2020-09-01\")\n",
    "\n",
    "list(root.walk(\"2020-07-01\", \"2020-09-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "def cmp(a, b):\n",
    "     return ((a > b) - (a < b))\n",
    "\n",
    "class BTree():\n",
    "    def __init__(self, leaf, M, key, value):\n",
    "        self.leaf = leaf\n",
    "        self.children = []\n",
    "        self.M = M\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "    \n",
    "    def walk(self):\n",
    "        for child in self.children:\n",
    "            if child.leaf:\n",
    "                yield child\n",
    "            yield from child.walk()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \" \".join(map(lambda x: \"{}:{} [{}]\".format(x.key, x.value, str(x)), self.children))  \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \" \".join(map(lambda x: \"{}:{} [{}]\".format(x.key, x.value, str(x)), self.children))\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        if len(self.children) == self.M:\n",
    "            print(\"We need to split\")\n",
    "            print(self)\n",
    "            for item in self.walk():\n",
    "                print(item.key, item.value)\n",
    "            new_root = BTree(False, self.M, 0, None)\n",
    "            new_sibling = BTree(False, self.M, 0, None)\n",
    "            midpoint = int((len(self.children)+1)/2)\n",
    "            \n",
    "            new_root.key = self.children[midpoint].key\n",
    "            new_root.value = self.children[midpoint].value          \n",
    "                        \n",
    "            print(\"Midpoint is \" + str(midpoint))\n",
    "            # del self.children[midpoint]\n",
    "            left_children = self.children[0:midpoint]\n",
    "            right_children = self.children[midpoint:]\n",
    "            for child in left_children:\n",
    "                print(\"{} goes to the left\".format(child.key))\n",
    "            for child in right_children:\n",
    "                print(\"{} goes to the right\".format(child.key))\n",
    "            new_root.children = [self, new_sibling]\n",
    "\n",
    "            new_sibling.key = right_children[0].key\n",
    "            new_sibling.value = right_children[0].value\n",
    "            \n",
    "            self.children = left_children\n",
    "            new_sibling.children = right_children\n",
    "            \n",
    "            self.leaf = False\n",
    "            \n",
    "            self.key = left_children[0].key\n",
    "            self.value = left_children[0].value\n",
    "            \n",
    "            split = new_root.insertAfterSplit(key, value)\n",
    "            \n",
    "            return new_root\n",
    "        else:\n",
    "            \n",
    "            if not self.leaf:\n",
    "                \n",
    "                split = self.insertAfterSplit(key, value)\n",
    "             \n",
    "                               \n",
    "                return self\n",
    "            else:\n",
    "                split = self.insertAfterSplit(key, value)\n",
    "                return split\n",
    "                \n",
    "            return self\n",
    "\n",
    "    def insertAfterSplit(self, key, value):\n",
    "        \n",
    "        insertion_point, index = self.find_location_for_key(key)\n",
    "        if insertion_point == None:\n",
    "            self.insertNonFull(key, value)\n",
    "        else:\n",
    "            split = insertion_point.insert(key, value)\n",
    "            \n",
    "            return split\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def insertNonFull(self, key, value):\n",
    "        split = self\n",
    "        values = [child.key for child in self.children]\n",
    "        new_pos = bisect.bisect(values, key)\n",
    "        self.children.insert(new_pos, BTree(True, self.M, key, value))\n",
    "        return self\n",
    "\n",
    "    def find_location_for_key(self, key):\n",
    "        index = None\n",
    "        for child in self.children:\n",
    "            if cmp(key, child.key) >= 0:\n",
    "                  index = child, self.children.index(child)\n",
    "        if index:\n",
    "            return index\n",
    "        else:\n",
    "            return None, -1\n",
    "        \n",
    "    def delete(self, key):\n",
    "        deletion_point, index = self.find_location_for_key(key)\n",
    "        if deletion_point:\n",
    "            if deletion_point.key == key:\n",
    "                self.children.remove(deletion_point)\n",
    "                return True\n",
    "            else:\n",
    "                return deletion_point.delete(key)\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "root = BTree(False, 3, 0, None)\\\n",
    ".insert(8, \"big\")\\\n",
    ".insert(2, \"hello\")\\\n",
    ".insert(3, \"world\")\\\n",
    ".insert(6, \"cabbage\")\\\n",
    ".insert(1, \"cool\")\\\n",
    ".insert(7, \"broken\")\\\n",
    ".insert(4, \"stillbroken\")\\\n",
    ".insert(5, \"borked\")\\\n",
    ".insert(9, \"doesitwork\")\\\n",
    ".insert(10, \"Anatasya\")\n",
    "\n",
    "\n",
    "print(root.children)\n",
    "    \n",
    "for item in root.walk():\n",
    "    print(item.key, item.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = BTree(False, 3, 0, None)\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(1, 100):\n",
    "    num1 = random.randint(0, 100)\n",
    "    root.insert(num1, str(num1))\n",
    "\n",
    "for item in root.walk():\n",
    "    print(item.key, item.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = BTree(False, 3, 0, None)\\\n",
    ".insert(1, \"big\")\\\n",
    ".insert(2, \"hello\")\\\n",
    ".insert(3, \"world\")\\\n",
    ".insert(4, \"small\")\n",
    "\n",
    "for i in range(1, 100):\n",
    "    root = root.insert(i, str(i))\n",
    "\n",
    "for item in root.walk():\n",
    "    print(item.key, item.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = BTree(False, 4, 0, None)\\\n",
    ".insert(8, \"big\")\\\n",
    ".insert(2, \"hello\")\\\n",
    ".insert(3, \"world\")\\\n",
    ".insert(6, \"cabbage\")\\\n",
    ".insert(1, \"cool\")\\\n",
    ".insert(7, \"broken\")\\\n",
    ".insert(4, \"stillbroken\")\\\n",
    ".insert(5, \"borked\")\\\n",
    ".insert(9, \"doesitwork\")\n",
    "\n",
    "print(root.delete(7))\n",
    "\n",
    "for item in root.walk():\n",
    "    print(item.key, item.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "items = [\n",
    "    {\"key\": \"C.keyword.0\", \"value\": \"databases\"},\n",
    "    {\"key\": \"C.keyword.1\", \"value\": \"cat\"},\n",
    "    {\"key\": \"C.keyword.2\", \"value\": \"car\"},\n",
    "    {\"key\": \"C.keyword.3\", \"value\": \"cat\"},\n",
    "    {\"key\": \"C.searchterm.0\", \"value\": \"search\"},\n",
    "    {\"key\": \"R.people.0.id\", \"value\": 0},\n",
    "    {\"key\": \"R.people.1.id\", \"value\": 1},\n",
    "    {\"key\": \"R.people.1.people_name\", \"value\": \"Paul\"},\n",
    "    {\"key\": \"R.people.1.age\", \"value\": 26},\n",
    "    {\"key\": \"R.people.0.people_name\", \"value\": \"Samuel\"},\n",
    "    {\"key\": \"R.people.0.age\", \"value\": 30},\n",
    "    {\"key\": \"R.items.0.search\", \"value\": \"Things\"},\n",
    "    {\"key\": \"R.items.0.id\", \"value\": 0},\n",
    "    {\"key\": \"R.items.1.search\", \"value\": \"Others\"},\n",
    "    {\"key\": \"R.items.1.id\", \"value\": 1},\n",
    "    {\"key\": \"R.items.0.people\", \"value\": 0},\n",
    "    {\"key\": \"R.items.1.people\", \"value\": 1},\n",
    "    {\"key\": \"R.products.0.id\", \"value\": 0},\n",
    "    {\"key\": \"R.products.0.name\", \"value\": \"Things\"},\n",
    "    {\"key\": \"R.products.1.id\", \"value\": 1},\n",
    "    {\"key\": \"R.products.1.name\", \"value\": \"Others\"},\n",
    "    {\"key\": \"R.products.1.price\", \"value\": 20},\n",
    "    {\"key\": \"R.products.0.price\", \"value\": 30},\n",
    "]\n",
    "items = sorted(items, key=itemgetter(\"key\"))\n",
    "pprint(items)\n",
    "\n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.last_char = \" \"\n",
    "        self.pos = 0\n",
    "        self.select_clause = []\n",
    "        self.join_clause = []\n",
    "        self.end = False\n",
    "        self.group_by = None\n",
    "        self.insert_fields = []\n",
    "        self.insert_values = []\n",
    "        self.where_clause = []\n",
    "        self.fts_clause = []\n",
    "        \n",
    "\n",
    "    def getchar(self):\n",
    "        \n",
    "        char = self.statement[self.pos]\n",
    "        if self.pos + 1 == len(self.statement):\n",
    "            self.end = True\n",
    "            return char\n",
    "        self.pos = self.pos + 1\n",
    "        \n",
    "        return char\n",
    "        \n",
    "    def gettok(self):\n",
    "        while (self.end == False and (self.last_char == \" \" or self.last_char == \"\\n\")):\n",
    "            self.last_char = self.getchar()\n",
    "        \n",
    "        \n",
    "              \n",
    "        if self.last_char == \"(\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"openbracket\"\n",
    "        \n",
    "        if self.last_char == \")\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"closebracket\"\n",
    "        \n",
    "        if self.last_char == \"*\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"wildcard\"\n",
    "        \n",
    "        if self.last_char == \"'\":\n",
    "            self.last_char = self.getchar()\n",
    "            identifier = \"\"\n",
    "            while self.end == False and self.last_char != \"'\":\n",
    "                if self.last_char == \"\\\\\":\n",
    "                    self.last_char = self.getchar()\n",
    "                identifier = identifier + self.last_char\n",
    "                self.last_char = self.getchar()\n",
    "            if self.end and self.last_char != \")\" and self.last_char != \"'\":\n",
    "                identifier += self.last_char\n",
    "            \n",
    "            self.last_char = self.getchar()\n",
    "            \n",
    "            return identifier\n",
    "        \n",
    "        if re.match(\"[a-zA-Z0-9\\.\\_]+\", self.last_char):\n",
    "            identifier = \"\"\n",
    "            while self.end == False and re.match(\"[a-zA-Z0-9\\.\\_]+\", self.last_char):\n",
    "                \n",
    "                identifier = identifier + self.last_char\n",
    "                self.last_char = self.getchar()\n",
    "            \n",
    "            if self.end and self.last_char != \")\":\n",
    "                identifier += self.last_char\n",
    "            \n",
    "            return identifier\n",
    "    \n",
    "        if self.last_char == \"=\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"eq\"\n",
    "        \n",
    "        if self.last_char == \"~\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"tilde\"\n",
    "        \n",
    "        if self.last_char == \",\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"comma\"\n",
    "        \n",
    "        if self.end:\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def parse_select(self, token=None):\n",
    "        if token == None:\n",
    "            token = self.gettok()\n",
    "        if token == \"comma\":\n",
    "            self.parse_select()\n",
    "        elif token == \"from\":\n",
    "            self.table_name = self.gettok()\n",
    "            self.parse_rest()\n",
    "        elif token != None:\n",
    "            identifier = token\n",
    "            \n",
    "            token = self.gettok()\n",
    "            if token == \"openbracket\": # we're in a function\n",
    "                function_parameters = self.gettok()\n",
    "                if function_parameters == \"wildcard\":\n",
    "                    function_parameters = \"*\"\n",
    "            else:\n",
    "                if identifier == \"wildcard\":\n",
    "                    identifier = \"*\"\n",
    "                self.select_clause.append(identifier)\n",
    "                self.parse_select(token)\n",
    "                return\n",
    "            closebracket = self.gettok()\n",
    "            \n",
    "            self.select_clause.append(identifier + \"(\" + function_parameters + \")\")\n",
    "            self.parse_select()\n",
    "    \n",
    "    def parse_rest(self):\n",
    "        operation = self.gettok()\n",
    "        print(operation)\n",
    "        if operation == None:\n",
    "            return\n",
    "        if operation == \"group\":\n",
    "            by = self.gettok()\n",
    "            group_by = self.gettok()\n",
    "            self.group_by = group_by\n",
    "            \n",
    "        if operation == \"inner\":\n",
    "            join = self.gettok()\n",
    "            self.join_table = self.gettok()\n",
    "            on = self.gettok()\n",
    "            join_target_1 = self.gettok()\n",
    "            \n",
    "            self.gettok()\n",
    "            join_target_2 = self.gettok()\n",
    "            self.join_clause.append([join_target_1, join_target_2])\n",
    "            self.parse_rest()\n",
    "            \n",
    "        if operation == \"where\":\n",
    "            self.parse_where()\n",
    "            \n",
    "    def parse_where(self):\n",
    "        field = self.gettok()\n",
    "        equals = self.gettok()\n",
    "        value = self.gettok()\n",
    "        print(equals)\n",
    "        print(value)\n",
    "        if re.match(\"[0-9\\.]+\", value):\n",
    "            value = int(value)\n",
    "        print(\"Equals operator:\" + equals)\n",
    "        if equals == \"eq\":\n",
    "            self.where_clause.append((field, value))\n",
    "        if equals == \"tilde\":\n",
    "            self.fts_clause.append((field, value))\n",
    "        another = self.gettok()\n",
    "        if another == \"and\":\n",
    "            self.parse_where()\n",
    "        \n",
    "    \n",
    "    def parse_insert_fields(self):\n",
    "        field_name = self.gettok()\n",
    "        self.insert_fields.append(field_name)\n",
    "    \n",
    "        token = self.gettok()\n",
    "        if token == \"closebracket\":\n",
    "            self.parse_rest_insert()\n",
    "        if token == \"comma\":\n",
    "            self.parse_insert_fields()\n",
    "    \n",
    "    def parse_values(self):\n",
    "        value = self.gettok()\n",
    "        if re.match(\"[0-9\\.]+\", value):\n",
    "            value = int(value)\n",
    "        self.insert_values.append(value)\n",
    "       \n",
    "        token = self.gettok()\n",
    "        \n",
    "        if token == \"comma\":\n",
    "            self.parse_values()\n",
    "        if token == \"closebracket\":\n",
    "            print(\"We have finished parsing insert into\")\n",
    "            \n",
    "        \n",
    "    def parse_rest_insert(self):\n",
    "        values = self.gettok()\n",
    "        if values == \"values\":\n",
    "            openbracket = self.gettok()\n",
    "            self.parse_values()\n",
    "    \n",
    "    def parse_insert(self):\n",
    "        self.insert_table = self.gettok()\n",
    "        openbracket = self.gettok()\n",
    "        \n",
    "        if openbracket == \"openbracket\":\n",
    "            self.parse_insert_fields()\n",
    "    \n",
    "    def parse(self, statement):\n",
    "        self.statement = statement\n",
    "        token = self.gettok()\n",
    "        if token == \"select\":\n",
    "            self.parse_select()\n",
    "        if token == \"insert\":\n",
    "            into = self.gettok()\n",
    "            self.parse_insert()\n",
    "       \n",
    "\n",
    "\n",
    "class SQLExecutor:\n",
    "    def __init__(self, parser):\n",
    "        self.parser = parser\n",
    "    \n",
    "    def get_tables(self, table_def):\n",
    "        table_datas = []\n",
    "        for pair in table_def:\n",
    "            pair_data = []\n",
    "            for selector in pair:\n",
    "                table, field = selector.split(\".\")\n",
    "                row_filter = \"R.{}\".format(table)\n",
    "                table_data = list(filter(lambda x: x[\"key\"].startswith(row_filter), items))\n",
    "                pair_data.append((table_data, field))\n",
    "            table_datas.append(pair_data)\n",
    "\n",
    "\n",
    "        def table_reductions(table, metadata):\n",
    "            for record in table:\n",
    "                yield from reduce_table(metadata, record)\n",
    "            yield metadata[\"current_record\"]\n",
    "\n",
    "        def reduce_table(table_metadata, record):\n",
    "            components = record[\"key\"].split(\".\")\n",
    "            identifier = components[2]\n",
    "            field_name = components[3]\n",
    "            last_id = table_metadata[\"current_record\"].get(\"internal_id\")\n",
    "            if last_id == None:\n",
    "                table_metadata[\"current_record\"] = {}\n",
    "                table_metadata[\"current_record\"][\"internal_id\"] = identifier\n",
    "                table_metadata[\"current_record\"][field_name] = record[\"value\"]\n",
    "            elif last_id != identifier:\n",
    "                yield table_metadata[\"current_record\"]\n",
    "                # reset\n",
    "                table_metadata[\"current_record\"] = {}\n",
    "                table_metadata[\"current_record\"][\"internal_id\"] = identifier\n",
    "                table_metadata[\"current_record\"][field_name] = record[\"value\"]\n",
    "            elif last_id == identifier:\n",
    "                table_metadata[\"current_record\"][field_name] = record[\"value\"]\n",
    "\n",
    "\n",
    "        field_reductions = []\n",
    "        for pair in table_datas:\n",
    "            pair_items = []\n",
    "            for item in pair:\n",
    "                table, join_field = item\n",
    "                field_reduction = table_reductions(table, defaultdict(dict))\n",
    "                pair_items.append(field_reduction)\n",
    "            field_reductions.append(pair_items)\n",
    "        return table_datas, field_reductions\n",
    "    \n",
    "    def hash_join(self, records, index, pair, table_datas, process_records=True):\n",
    "        ids_for_key = defaultdict(list)\n",
    "        if process_records and len(records) > 0:\n",
    "            scan = records\n",
    "        else:\n",
    "            scan = pair[0]\n",
    "        \n",
    "        for item in scan:\n",
    "            field = table_datas[index][0][1]\n",
    "            \n",
    "            left_field = item[field]\n",
    "            ids_for_key[left_field] = item\n",
    "        \n",
    "        for item in pair[1]:\n",
    "            \n",
    "            if table_datas[index][1][1] in item and item[table_datas[index][1][1]] in ids_for_key:\n",
    "                item_value = item[table_datas[index][1][1]]\n",
    "                print(\"Found match: {} in ids_for_key\".format(item_value))\n",
    "                yield {**ids_for_key[item[table_datas[index][1][1]]], **item}\n",
    "    \n",
    "    def execute(self):\n",
    "        if self.parser.fts_clause:\n",
    "            # full text search\n",
    "            table_datas, field_reductions = self.get_tables([[\"{}.\".format(self.parser.table_name)]])\n",
    "            have_printed_header = False\n",
    "            header = []\n",
    "            output_lines = []\n",
    "            outputs = []\n",
    "            for result in self.process_wheres(field_reductions[0][0]):\n",
    "                print(\"item: \" + str(result))\n",
    "                output_lines = []\n",
    "                for field in self.parser.select_clause:\n",
    "\n",
    "                    if field == \"*\":\n",
    "                        for key, value in result.items():\n",
    "                            if not have_printed_header:\n",
    "                                header.append(key)\n",
    "                            output_lines.append(value)\n",
    "                    else:\n",
    "                        output_lines.append(result[field])\n",
    "                have_printed_header = True\n",
    "                outputs.append(output_lines)\n",
    "            print(header)\n",
    "            print(outputs)\n",
    "             \n",
    "            \n",
    "        elif self.parser.insert_values:\n",
    "            insert_table = self.parser.insert_table\n",
    "            print(\"Insert statement\")\n",
    "            created = False\n",
    "            new_insert_count = 1\n",
    "            for field, value in zip(self.parser.insert_fields, self.parser.insert_values):\n",
    "                table_datas, field_reductions = self.get_tables([[\"{}.\".format(insert_table)]])\n",
    "                if not created:\n",
    "                    new_insert_count = len(list(field_reductions[0][0])) + 1\n",
    "                \n",
    "                # create full text search index\n",
    "                if isinstance(value, str): \n",
    "                    tokens = value.replace(\",\", \"\").split(\" \")\n",
    "                    for token in tokens:\n",
    "                        new_key = \"FTS.{}.{}.{}.{}\".format(insert_table, field, token, new_insert_count)\n",
    "                        items.append({\n",
    "                            \"key\": new_key,\n",
    "                            \"value\": new_insert_count\n",
    "                        })\n",
    "                \n",
    "                \n",
    "                new_key = \"R.{}.{}.{}\".format(insert_table, new_insert_count, field)\n",
    "                items.append({\n",
    "                    \"key\": new_key,\n",
    "                    \"value\": value\n",
    "                })\n",
    "                new_key = \"S.{}.{}.{}.{}\".format(insert_table, field, value, new_insert_count)\n",
    "                items.append({\n",
    "                    \"key\": new_key,\n",
    "                    \"value\": new_insert_count\n",
    "                })\n",
    "                new_key = \"C.{}.{}.{}\".format(insert_table, field, new_insert_count)\n",
    "                items.append({\n",
    "                    \"key\": new_key,\n",
    "                    \"value\": value\n",
    "                })\n",
    "                if not created:\n",
    "                    new_key = \"R.{}.{}.id\".format(insert_table, new_insert_count, field)\n",
    "                    items.append({\n",
    "                        \"key\": new_key,\n",
    "                        \"value\": new_insert_count\n",
    "                    })\n",
    "                    created = True\n",
    "                items.sort(key=itemgetter('key'))\n",
    "            \n",
    "        elif self.parser.group_by:\n",
    "            print(\"Group by statement\")\n",
    "            group_by_components = parser.group_by.split(\".\")\n",
    "            aggregator = defaultdict(list)\n",
    "            row_specifier = \"C.{}.{}\".format(group_by_components[0], group_by_components[1])\n",
    "            for item in filter(lambda x: x[\"key\"].startswith(row_specifier), items):\n",
    "                k = item[\"key\"]\n",
    "                v = item[\"value\"]\n",
    "      \n",
    "                key_components = k.split(\".\")\n",
    "                \n",
    "                print(key_components[2])\n",
    "                if (key_components[1] == group_by_components[0]) and (key_components[2] == group_by_components[1]):\n",
    "                    aggregator[v].append(v)\n",
    "\n",
    "            print(statement)\n",
    "            for k, v in aggregator.items():\n",
    "                output_line = \"\"\n",
    "                for item in parser.select_clause:\n",
    "                    if \"count\" in item:\n",
    "                        output_line += str(len(aggregator[k]))\n",
    "                    else:\n",
    "                        output_line += str(k) + \" \"\n",
    "                print(output_line)\n",
    "                \n",
    "        elif self.parser.join_clause:\n",
    "            table_datas, field_reductions = self.get_tables(self.parser.join_clause)\n",
    "\n",
    "            records = []\n",
    "            for index, pair in enumerate(field_reductions):\n",
    "                records = list(self.hash_join(records, index, pair, table_datas))\n",
    "            \n",
    "            records = self.process_wheres(records)\n",
    "            print(\"records from join\" + str(records))\n",
    "            \n",
    "            for record in records:\n",
    "                output_line = []\n",
    "                for clause in parser.select_clause:\n",
    "                    table, field = clause.split(\".\")\n",
    "                    output_line.append(record[field])\n",
    "                print(output_line)\n",
    "                \n",
    "        elif self.parser.select_clause:\n",
    "            table_datas, field_reductions = self.get_tables([[\"{}.\".format(self.parser.table_name)]])\n",
    "            have_printed_header = False\n",
    "            header = []\n",
    "            output_lines = []\n",
    "            for result in self.process_wheres(field_reductions[0][0]):\n",
    "                print(\"item: \" + str(result))\n",
    "                for field in self.parser.select_clause:\n",
    "\n",
    "                    if field == \"*\":\n",
    "                        for key, value in result.items():\n",
    "                            if not have_printed_header:\n",
    "                                header.append(key)\n",
    "                            output_lines.append(value)\n",
    "                    else:\n",
    "                        output_lines.append(result[field])\n",
    "                have_printed_header = True\n",
    "            print(header)\n",
    "            print(output_lines)\n",
    "    \n",
    "    def process_wheres(self, field_reductions):\n",
    "        where_clause = self.parser.where_clause\n",
    "        fts_clause = self.parser.fts_clause\n",
    "        data = list(field_reductions)\n",
    "        records = []\n",
    "        if not where_clause and not fts_clause:\n",
    "            return field_reductions\n",
    "        reductions = []\n",
    "        table_datas = []\n",
    "        and_or = []        \n",
    "        \n",
    "        for restriction, value in fts_clause:\n",
    "            print(\"Running FTS search for where clause value \" + str(value))\n",
    "            table, field = restriction.split(\".\")\n",
    "            tokens = value.split(\" \")\n",
    "            mode = \"and\"\n",
    "            for token in tokens:\n",
    "                if token == \"&\" or token == \"|\":\n",
    "                    if token == \"&\":\n",
    "                        mode = \"and\"\n",
    "                    if token == \"|\":\n",
    "                        mode = \"or\"\n",
    "                    continue\n",
    "                and_or.append(mode)\n",
    "                row_filter = \"FTS.{}.{}.{}\".format(table, field, token)\n",
    "                table_data = list(map(lambda x: {\"id\": x[\"value\"]}, filter(lambda x: x[\"key\"].startswith(row_filter), items)))\n",
    "                \n",
    "                reductions.append([data, table_data])\n",
    "                table_datas.append([(data, \"id\"), (table_data, \"id\")])\n",
    "        \n",
    "        for restriction, value in where_clause:\n",
    "            print(\"Running hash join for where clause value \" + str(value))\n",
    "            table, field = restriction.split(\".\")\n",
    "            and_or.append(\"and\")\n",
    "            row_filter = \"S.{}.{}.{}\".format(table, field, value)\n",
    "            table_data = list(map(lambda x: {\"id\": x[\"value\"]}, filter(lambda x: x[\"key\"].startswith(row_filter), items)))\n",
    "            reductions.append([table_data, data])\n",
    "            table_datas.append([(table_data, \"id\"), (data, \"id\")])\n",
    "        \n",
    "        process_records = True\n",
    "        \n",
    "        for index, pair in enumerate(reductions):\n",
    "            if and_or[index] == \"and\":\n",
    "                records = list(self.hash_join(records, index, pair, table_datas, process_records=True))\n",
    "                \n",
    "            if and_or[index] == \"or\":\n",
    "                matched = list(self.hash_join(records, index, pair, table_datas, process_records=False))\n",
    "                if matched:\n",
    "                    records = records + matched\n",
    "            print(records)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return records\n",
    "        \n",
    "print(\"Inserting ted\")\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into people (people_name, age) values ('Ted', 29)\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "print(\"Inserted ted\")\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into products (name, price) values ('Cat', 100)\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into products (name, price) values ('Tree', 50)\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into items (search) values ('Tree')\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into items (search, people) values ('Cat', 3)\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "pprint(items)\n",
    "\n",
    "statement = \"\"\"select products.price, people.people_name,\n",
    "    items.search from items inner join people on people.id = items.people\n",
    "    inner join products on items.search = products.name\n",
    "    \n",
    "    \"\"\"\n",
    "# where people.people_name = 'Ted'\n",
    "print(statement)\n",
    "parser = Parser()\n",
    "parser.parse(statement)\n",
    "print(\"parsed\")\n",
    "\n",
    "SQLExecutor(parser).execute()\n",
    "print(\"executed\")\n",
    "statement = \"select * from people where people.people_name = 'Ted' and people.age = 29\"\n",
    "parser = Parser()\n",
    "parser.parse(statement)\n",
    "print(parser.select_clause)\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "statement = \"select * from items where items.search = 'Tree'\"\n",
    "parser = Parser()\n",
    "parser.parse(statement)\n",
    "print(parser.select_clause)\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "statement = \"select search, count(*) from items group by items.search\"\n",
    "parser = Parser()\n",
    "parser.parse(statement)\n",
    "\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into items (search, people) values ('A long sentence', 3)\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(\"insert into items (search, people) values ('blah sentence', 3)\")\n",
    "SQLExecutor(parser).execute()\n",
    "\n",
    "pprint(items)\n",
    "\n",
    "statement = \"select * from items where items.search ~ 'blah & sentence' where items.people = 3\"\n",
    "parser = Parser()\n",
    "parser.parse(statement)\n",
    "\n",
    "SQLExecutor(parser).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"fixed_value_sim {\n",
    "  Time 1 us\n",
    "  Declared: {val1[31:0]}                   VHDL    3\n",
    "\n",
    "  Declared: {shtdwn_counter}               VHDL    0\n",
    "\n",
    "\n",
    "  Declared: {clk_counter}                  VHDL    90\n",
    "\n",
    "}\"\"\"\n",
    "import re\n",
    "import pprint\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.pos = 0\n",
    "        self.char = \" \"\n",
    "        self.end = False\n",
    "        self.block_name = \"\"\n",
    "        self.time_units = ()\n",
    "        self.lines = []\n",
    "        self.block = {}\n",
    "    def gettok(self):\n",
    "        while self.char == \" \" or self.char == \"\\n\":\n",
    "            self.char = self.getchar()      \n",
    "        \n",
    "        if self.char == \"{\":\n",
    "            self.char = self.getchar()\n",
    "            return \"curlyopen\"\n",
    "        \n",
    "        if self.char == \":\":\n",
    "            self.char = self.getchar()\n",
    "            return \"definition\"\n",
    "        \n",
    "        if self.char == \"}\":\n",
    "            self.char = self.getchar()\n",
    "            return \"curlyclose\"\n",
    "      \n",
    "        if re.match(\"[a-zA-Z0-9\\.\\_[\\\\]:]+\", self.char):\n",
    "            identifier = \"\"\n",
    "            while self.end == False and re.match(\"[a-zA-Z0-9\\.\\_[\\\\]:]+\", self.char):\n",
    "                identifier = identifier + self.char\n",
    "                self.char = self.getchar()\n",
    "                \n",
    "            return identifier\n",
    "    \n",
    "        \n",
    "        \n",
    "    def parse_block(self):\n",
    "        token = self.gettok()\n",
    "\n",
    "        if token == \"Time\":\n",
    "            amount = self.gettok()\n",
    "            unit = self.gettok()\n",
    "            self.time_units = (amount, unit)\n",
    "            self.parse_block()\n",
    "            return\n",
    "        if token == \"Declared:\":\n",
    "            curlyopen = self.gettok()\n",
    "            field = self.gettok()\n",
    "            curlyclose = self.gettok()\n",
    "            kind = self.gettok()\n",
    "            amount = self.gettok()\n",
    "            \n",
    "            self.lines.append((self.time_units, field, kind, amount))\n",
    "            if self.block_name not in self.block:\n",
    "                self.block[self.block_name] = {}\n",
    "            self.block[self.block_name][field] = (self.time_units, kind, amount)\n",
    "            self.time_units = None\n",
    "            self.parse_block()\n",
    "        if token == \"curlyclose\":\n",
    "            print(\"Finished parsing\")\n",
    "        \n",
    "    def parse(self, statement):\n",
    "        self.statement = statement\n",
    "        self.block_name = self.gettok()\n",
    "        \n",
    "        token = self.gettok()\n",
    "        if token == \"curlyopen\":\n",
    "            self.parse_block()\n",
    "        \n",
    "        \n",
    "    def getchar(self):\n",
    "        if self.pos + 1 > len(self.statement):\n",
    "            self.end = True\n",
    "            print(\"end of the line\")\n",
    "            return \"\"\n",
    "        char = self.statement[self.pos]\n",
    "        self.pos = self.pos + 1\n",
    "        return char\n",
    "\n",
    "parser = Parser()\n",
    "parser.parse(string)\n",
    "print(parser.lines)\n",
    "pprint.pprint(parser.block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wantsfile = \"\"\"wants:\n",
    "- group_name: groceries\n",
    "  delivery: 5\n",
    "  wants:\n",
    "    - name: 4 pints semi skimmed milk\n",
    "      price: 1.50\n",
    "      quantity: 1\n",
    "    - name: 100g milk chocolate\n",
    "      price: 1.50\n",
    "      quantity: 1\n",
    "\"\"\"\n",
    "\n",
    "sellfile = \"\"\"sell:\n",
    "- name: 4 pints semi skimmed milk\n",
    "  price: 1.43\n",
    "- name: 4 pints semi skimmed milk\n",
    "  price: 1.46\n",
    "- name: 4 pints semi skimmed milk\n",
    "  price: 1.48\n",
    "- name: 100g milk chocolate\n",
    "  price: 1.50\n",
    "- name: 100g milk chocolate\n",
    "  price: 1.60\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "from operator import itemgetter\n",
    "import collections\n",
    "from pprint import pprint\n",
    "products = collections.defaultdict(dict)\n",
    "\n",
    "wantsfile = yaml.safe_load(wantsfile)\n",
    "\n",
    "for group in wantsfile[\"wants\"]:\n",
    "    for product in group[\"wants\"]:\n",
    "        product_name = product[\"name\"]\n",
    "        if \"buy\" not in products[product_name]:\n",
    "            products[product_name][\"buy\"] = []\n",
    "        products[product_name][\"buy\"].append(product)\n",
    "        product[\"group_name\"] = group[\"group_name\"]\n",
    "\n",
    "for product in yaml.safe_load(sellfile)[\"sell\"]:\n",
    "    product_name = product[\"name\"]\n",
    "    if \"sell\" not in products[product_name]:\n",
    "            products[product_name][\"sell\"] = []\n",
    "    products[product_name][\"sell\"].append(product)\n",
    "\n",
    "pprint(products)\n",
    "matched_products = []\n",
    "# order matching\n",
    "for product, value in products.items():\n",
    "    for index, item in enumerate(value[\"buy\"]):\n",
    "        item[\"index\"] = index\n",
    "        item[\"price\"] = int(float(re.sub(\"[^-0-9.,]\", '', item[\"price\"])) * 100)\n",
    "    for index, item in enumerate(value[\"sell\"]):\n",
    "        item[\"index\"] = index\n",
    "        item[\"price\"] = int(float(re.sub(\"[^-0-9.,]\", '', item[\"price\"])) * 100)\n",
    "    value[\"buy\"].sort(key=lambda x: (x[\"price\"], x[\"index\"]), reverse=True)\n",
    "    value[\"sell\"].sort(key=lambda x: (x[\"price\"], x[\"index\"]))\n",
    "    \n",
    "   \n",
    "    first_buy = value[\"buy\"][0]\n",
    "    first_sell = value[\"sell\"][0]\n",
    "    \n",
    "    if first_buy[\"price\"] >= first_sell[\"price\"]:\n",
    "        print(\"{}: buy {} matches with sell {}\".format(product, first_buy[\"price\"], first_sell[\"price\"]))\n",
    "        price = (first_buy[\"price\"] + first_sell[\"price\"]) / 2\n",
    "        matched_purchase = (price, first_buy, first_sell)\n",
    "        matched_products.append(matched_purchase)\n",
    "        first_buy[\"matched\"] = matched_purchase\n",
    "    else:\n",
    "        print(\"Failed to match\")\n",
    "\n",
    "for group in wantsfile[\"wants\"]:\n",
    "    if all(map(lambda product: product.get(\"matched\") is not None, group[\"wants\"])):\n",
    "        print(group[\"group_name\"], \"is satisfied\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello Natasha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentence = \"\"\"I eat pizza\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"ID\": 1,\n",
    "    \"Name\": \"Edward the Elder\",\n",
    "    \"Country\": \"United Kingdom\",\n",
    "    \"House\": \"House of Wessex\",\n",
    "    \"Reign\": \"899-925\",\n",
    "    \"nested\": [{\"subobject\": \"hello\"}, {\"subobject2\": \"world\"}]\n",
    "  },\n",
    "  {\n",
    "    \"ID\": 2,\n",
    "    \"Name\": \"Athelstan\",\n",
    "    \"Country\": \"United Kingdom\",\n",
    "    \"House\": \"House of Wessex\",\n",
    "    \"Reign\": \"925-940\"\n",
    "  },\n",
    "  {\n",
    "    \"ID\": 3,\n",
    "    \"Name\": \"Edmund\",\n",
    "    \"Country\": \"United Kingdom\",\n",
    "    \"House\": \"House of Wessex\",\n",
    "    \"Reign\": \"940-946\"\n",
    "  },\n",
    "  {\n",
    "    \"ID\": 4,\n",
    "    \"Name\": \"Edred\",\n",
    "    \"Country\": \"United Kingdom\",\n",
    "    \"House\": \"House of Wessex\",\n",
    "    \"Reign\": \"946-955\"\n",
    "  },\n",
    "  {\n",
    "    \"ID\": 5,\n",
    "    \"Name\": \"Edwy\",\n",
    "    \"Country\": \"United Kingdom\",\n",
    "    \"House\": \"House of Wessex\",\n",
    "    \"Reign\": \"955-959\"\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "import re\n",
    "from pprint import pprint\n",
    "class Access():\n",
    "    def __init__(self, parser, path):\n",
    "        self.parser = parser\n",
    "        self.path = str(path)\n",
    "        self.n = 0\n",
    "        self.highest = 0\n",
    "        self.kv_iteration = False\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        new_path = self.path + \">\" + str(item)\n",
    "        if new_path in self.parser.kv:\n",
    "            return self.parser.kv[new_path]\n",
    "        else:\n",
    "            return Access(self.parser, new_path)\n",
    "    \n",
    "    def value(self):\n",
    "        if self.path in self.parser.kv:\n",
    "            return self.parser.kv[self.path]\n",
    "        else:\n",
    "            return Access(self.parser, self.path)\n",
    "    \n",
    "    def has_value(self):\n",
    "        return self.path in self.parser.kv\n",
    "    \n",
    "    def enable_kv_iterator(self):\n",
    "        self.kv_iteration = True\n",
    "    \n",
    "    def __len__(self):\n",
    "        lenstring = self.path + \":len\"\n",
    "        if lenstring in self.parser.kv:\n",
    "            return int(self.parser.kv[lenstring])\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        self.highest = len(self)\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        \n",
    "        if self.n < self.highest:\n",
    "            access_string = self.path + \">\" + str(self.n)\n",
    "            \n",
    "            \n",
    "            self.n += 1\n",
    "            if self.kv_iteration:\n",
    "                data = {}\n",
    "                keys = self.parser.kv[(access_string + \":obj\")].split(\",\")\n",
    "                print(keys)\n",
    "                for key in keys:\n",
    "                    new_path = access_string + \">\" + str(key)\n",
    "                    print(new_path)\n",
    "                    if new_path in self.parser.kv:\n",
    "                        data[key] = self.parser.kv[new_path]\n",
    "                return data\n",
    "            else:\n",
    "                subaccess = Access(self.parser, access_string)\n",
    "                if subaccess.has_value():\n",
    "                    return subaccess.value()\n",
    "                return subaccess\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        \n",
    "    \n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.char = \" \"\n",
    "        self.end = False\n",
    "        self.pos = 0\n",
    "        self.arrays = []\n",
    "        self.objects = []\n",
    "        self.kv = {}\n",
    "        \n",
    "    def getchar(self):\n",
    "        if self.pos + 1 > len(self.statement):\n",
    "            self.end = True\n",
    "            return \"\"\n",
    "        \n",
    "        char = self.statement[self.pos]\n",
    "        self.pos = self.pos + 1\n",
    "        return char\n",
    "    \n",
    "    def gettok(self):\n",
    "        while self.char == \" \" or self.char == \"\\n\":\n",
    "            self.char = self.getchar()\n",
    "        \n",
    "        if self.char == \"{\":\n",
    "            self.char = self.getchar()\n",
    "            return \"curlyopen\"\n",
    "        \n",
    "        if self.char == \"}\":\n",
    "            self.char = self.getchar()\n",
    "            return \"curlyclose\"\n",
    "        \n",
    "        if self.char == \":\":\n",
    "            self.char = self.getchar()\n",
    "            return \"colon\"\n",
    "        \n",
    "        if self.char == \"[\":\n",
    "            self.char = self.getchar()\n",
    "            return \"squareopen\"\n",
    "        \n",
    "        if self.char == \"]\":\n",
    "            self.char = self.getchar()\n",
    "            return \"squareclose\"\n",
    "        \n",
    "        if self.char == \",\":\n",
    "            self.char = self.getchar()\n",
    "            return \"comma\"\n",
    "        \n",
    "        if self.char == \"\\\"\":\n",
    "            identifier = \"\"\n",
    "            self.char = self.getchar()\n",
    "            while not self.end and re.match(\"[a-zA-Z0-9- ]+\", self.char) and self.char != \"\\\"\":\n",
    "                identifier = identifier + self.char\n",
    "                self.char = self.getchar()\n",
    "            \n",
    "            if self.char == \"\\\"\":\n",
    "                self.char = self.getchar()\n",
    "            \n",
    "            return identifier\n",
    "    \n",
    "        \n",
    "        if re.match(\"[a-zA-Z0-9]+\", self.char):\n",
    "            identifier = \"\"\n",
    "            while not self.end and re.match(\"[a-zA-Z0-9]+\", self.char):\n",
    "                identifier = identifier + self.char\n",
    "                self.char = self.getchar()\n",
    "            return identifier\n",
    "        \n",
    "        print(\"[\", self.statement[self.pos], \"]\")\n",
    "    \n",
    "    def begin_object(self, path=\"\"):\n",
    "        token = \"\"\n",
    "        keys = []\n",
    "        while not self.end and token != \"curlyclose\":\n",
    "            token = self.gettok()\n",
    "            \n",
    "            colon = self.gettok()\n",
    "            \n",
    "            value = self.gettok()\n",
    "            keys.append(token)\n",
    "            if value == \"curlyopen\":\n",
    "                self.begin_object(path=str(path) + \">\" + token)\n",
    "            elif value == \"squareopen\":\n",
    "                self.begin_array(path=str(path) + \">\" + token)\n",
    "            else:\n",
    "                if re.match(\"^[-]{0,1}[0-9.]+$\", value):\n",
    "                    value = int(value)\n",
    "                self.kv[str(path) + \">\" + token] = value\n",
    "            \n",
    "            token = self.gettok()\n",
    "            if token != \"comma\":\n",
    "                break\n",
    "        \n",
    "        if token == \"curlyclose\":\n",
    "            \n",
    "            self.kv[str(path) + \":obj\"] = \",\".join(keys)\n",
    "            return None\n",
    "        return token\n",
    "    \n",
    "    def begin_array(self, path=\"\"):\n",
    "        token = self.gettok()\n",
    "        index_position = 0\n",
    "        while not self.end and token != \"squareclose\":\n",
    "            if token == \"curlyopen\":\n",
    "                token = self.begin_object(path=path + \">\" + str(index_position))\n",
    "            elif token == \"squareopen\":\n",
    "                token = self.begin_array(path=path + \">\" + str(index_position))\n",
    "            else:\n",
    "                if re.match(\"[0-9.-]\", token):\n",
    "                    token = int(token)\n",
    "                self.kv[path + \">\" + str(index_position)] = token\n",
    "            \n",
    "            token = self.gettok()\n",
    "            \n",
    "                \n",
    "            if token == \"comma\":\n",
    "                index_position = index_position + 1\n",
    "                token = self.gettok()\n",
    "        \n",
    "        if token == \"squareclose\":\n",
    "            self.kv[path + \":len\"] = index_position + 1\n",
    "            \n",
    "        return token\n",
    "    \n",
    "    def parse(self, statement):\n",
    "        self.statement = statement\n",
    "        \n",
    "        token = self.gettok()\n",
    "        \n",
    "        if token == \"curlyopen\":\n",
    "            self.begin_object()\n",
    "        if token == \"squareopen\":\n",
    "            self.begin_array()\n",
    "            \n",
    "    \n",
    "    def access(self):\n",
    "        if \":len\" in self.kv:\n",
    "            return Access(self, \"\")\n",
    "        else:\n",
    "            return Access(self, \"\")\n",
    "            \n",
    "parser = Parser()\n",
    "parser.parse(json_data)\n",
    "pprint(parser.kv)\n",
    "\n",
    "print(parser.access()[0][\"nested\"][0][\"subobject\"])\n",
    "print(len(parser.access()[0][\"nested\"]))\n",
    "for item in parser.access()[0][\"nested\"]:\n",
    "    print(item[\"subobject\"])\n",
    "for item in parser.access():\n",
    "    print(item[\"Name\"])\n",
    "    \n",
    "access = parser.access()\n",
    "access.enable_kv_iterator()\n",
    "for item in access:\n",
    "    print(item)\n",
    "\n",
    "json_data = \"\"\"\n",
    "{\n",
    "    \"hello\": \"world\",\n",
    "    \"numbers\": [1,2,3,4,5]\n",
    "}\"\"\"\n",
    "parser = Parser()\n",
    "parser.parse(json_data)\n",
    "pprint(parser.kv)\n",
    "\n",
    "access = parser.access()\n",
    "access.enable_kv_iterator()\n",
    "for item in access[\"numbers\"]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = [\n",
    "    \"I ate <food-item>\",\n",
    "    \"I drunk <drink-item>\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadixTreeNode():\n",
    "    def __init__(self, root, key, value, isLeaf=False):\n",
    "  \n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.root = root\n",
    "        self.isLeaf = isLeaf\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.key\n",
    "    \n",
    "    def common_substring(self, value1, value2):\n",
    "        i = 0\n",
    "        while i < len(value1) and i < len(value2):\n",
    "            if value1[i] == value2[i]:\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        return (value1[0:i], i)\n",
    "    \n",
    "    def validate(self):\n",
    "        print(\"{} < {}\".format(self.left.key, self.key))\n",
    "        assert self.left.key < self.key\n",
    "        print(\"{} > {}\".format(self.right.key, self.key))\n",
    "        assert self.right.key > self.key\n",
    "        if self.left:\n",
    "            self.left.validate()\n",
    "        if self.right:\n",
    "            self.right.validate()\n",
    "    \n",
    "    def walk(self, path=\"\"):\n",
    "        if self.left:\n",
    "            yield from self.left.walk(path=path + \"left.\")\n",
    "        yield path + self.key\n",
    "        if self.right:\n",
    "            yield from self.right.walk(path=path + \"right.\")\n",
    "    \n",
    "    def prefixed(self, string):\n",
    "        prefixes, unmatched = self.find_prefixes_for_node(string)\n",
    "        print(\"Prefixes: {}\".format(prefixes))\n",
    "        path = \"\"\n",
    "        for prefix in prefixes:\n",
    "            path += prefix.key\n",
    "            yield path\n",
    "        yield from prefixes[-1].descend()\n",
    "    \n",
    "    def descend(self, path=\"\"):\n",
    "        if self.isLeaf:\n",
    "            yield path + self.key\n",
    "        if self.left:\n",
    "            yield from self.left.descend(path=path + self.key)\n",
    "        if self.right:\n",
    "            yield from self.right.descend(path=path + self.key)\n",
    "    \n",
    "    def find_prefixes_for_node(self, string):\n",
    "        if self.key is None:\n",
    "            return None, None\n",
    "        prefixes = []\n",
    "        string = self.find_prefixes_for_node_accum(prefixes, string)\n",
    "        return prefixes, string\n",
    "    \n",
    "    def find_prefixes_for_node_accum(self, accumulator, string):\n",
    "        if string.startswith(self.key):\n",
    "            accumulator.append(self)\n",
    "            string = string[len(self.key):]\n",
    "        if self.left:\n",
    "            string = self.left.find_prefixes_for_node_accum(accumulator, string)\n",
    "        \n",
    "        if self.right:\n",
    "            string = self.right.find_prefixes_for_node_accum(accumulator, string)\n",
    "        return string\n",
    "    \n",
    "    def handle_side(closest_prefix, self, side, key, value, unmatched):\n",
    "        print(\"Finding commonality between {} and {}\".format(side.key, key))\n",
    "        common_side, i = self.common_substring(self.key + side.key, key)\n",
    "        insert = False\n",
    "        if len(common_side) >= 1:\n",
    "            \n",
    "            original_right_key, original_value = side.key, side.value\n",
    "            common_side = common_side[len(self.key):]\n",
    "            side.key = common_side\n",
    "            \n",
    "            print(\"New node being created {}\".format(common_side))\n",
    "            original_key = (self.key + original_right_key)[i:]\n",
    "#             if (self.key + original_right_key)[i:] == \"\":\n",
    "#                 original_key = self.key\n",
    "            new_node = RadixTreeNode(self.root, key[i:], value, True)\n",
    "            original_node = RadixTreeNode(self.root, original_key, original_value)\n",
    "            \n",
    "            #if original_key > side.key and side.right != None:\n",
    "                \n",
    "            \n",
    "            if original_key > side.key:\n",
    "                \n",
    "                side.left = new_node\n",
    "                side.right = original_node\n",
    "            else:\n",
    "                \n",
    "                side.left = original_node\n",
    "                side.right = new_node\n",
    "            insert = True\n",
    "        return insert\n",
    "    \n",
    "    def insert(self, key, value, path=\"\"):\n",
    "        if self.key == None:\n",
    "            root_key = key[0:1]\n",
    "            root_rest = key[1:]\n",
    "            self.key = root_key\n",
    "            if root_rest > self.key:\n",
    "                self.right = RadixTreeNode(self.root, root_rest, value, True)\n",
    "            else:\n",
    "                self.left = RadixTreeNode(self.root, root_rest, value, True)\n",
    "        else:\n",
    "            split = None\n",
    "            \n",
    "            \n",
    "            print(\"{} trying to insert {}\".format(self.key, key))\n",
    "            prefixes, unmatched = self.find_prefixes_for_node(key)\n",
    "            print(\"Prefixes found:\")\n",
    "            print(prefixes)\n",
    "            print(\"Unmatched:\" + unmatched)\n",
    "            closest_prefix = None\n",
    "            if prefixes:\n",
    "                closest_prefix = prefixes[-1]\n",
    "\n",
    "            \n",
    "            if self.left:\n",
    "                print(self.left.key)\n",
    "            if self.right:\n",
    "                print(self.right.key)\n",
    "            if self.right == None and self.left != None and key[1:] > self.left.key:\n",
    "                print(\"Direct insert right\")\n",
    "                self.right = RadixTreeNode(self.root, key[1:], value)\n",
    "            elif self.left == None and self.right != None and key[1:] < self.right.key:\n",
    "                print(\"Direct insert left\")\n",
    "                self.left = RadixTreeNode(self.root, key[1:], value)\n",
    "            else:\n",
    "                print(\"need to find common roots of {} -> {} {} {}\".format(key, self.key,\n",
    "                                                                  self.left.key if self.left != None else \"\",\n",
    "                                                                  self.right.key if self.right != None else \"\"))\n",
    "                insert = False\n",
    "                \n",
    "                if self.left:\n",
    "                    print(\"Got left {}\".format(self.left.key))\n",
    "                    left_common, l_i = self.common_substring(self.key + self.left.key, key)\n",
    "                if self.right:\n",
    "                    print(\"Got right {}\".format(self.right.key))\n",
    "                    right_common, r_i = self.common_substring(self.key + self.right.key, key)\n",
    "                \n",
    "                if self.left and self.right:\n",
    "                    \n",
    "                    if len(left_common) > len(right_common):\n",
    "                        print(\"Left is bigger\")\n",
    "                        insert = self.handle_side(closest_prefix, self.left, key, value, unmatched)\n",
    "                    elif len(right_common) > len(left_common):\n",
    "                        print(\"Right is bigger\")\n",
    "                        insert = self.handle_side(closest_prefix, self.right, key, value, unmatched)\n",
    "                    \n",
    "                elif self.left:\n",
    "                    insert = self.handle_side(closest_prefix, self.left, key, value, unmatched)\n",
    "\n",
    "                elif self.right:\n",
    "                    insert = self.handle_side(closest_prefix, self.right, key, value, unmatched)\n",
    "                \n",
    "                if insert == False:\n",
    "                    if unmatched > closest_prefix.key:\n",
    "                        closest_prefix.right = RadixTreeNode(self.root, unmatched, value, True)\n",
    "                    else:\n",
    "                        closest_prefix.left = RadixTreeNode(self.root, unmatched, value, True)\n",
    "                \n",
    "#                     common_side, i = self.common_substring(self.key, key)\n",
    "#                     if key > self.key:\n",
    "#                         self.right = RadixTreeNode(key[i:], value)\n",
    "#                     else:\n",
    "#                         self.left = RadixTreeNode(key[i:], value)\n",
    "\n",
    "                return insert\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "class RadixTree():\n",
    "    def __init__(self, key, value):\n",
    "        self.roots = []\n",
    "    def insert(self, key, value):\n",
    "        found = None\n",
    "        for root in self.roots:\n",
    "            prefixes, unmatched = root.find_prefixes_for_node(key)\n",
    "            if prefixes != None and len(prefixes) > 0:\n",
    "                found = prefixes\n",
    "                print(\"INSERTING\")\n",
    "                root.insert(key, value)\n",
    "                break\n",
    "            \n",
    "        if found == None:\n",
    "            new_root = RadixTreeNode(self, key[:1], value)\n",
    "            new_remainder = RadixTreeNode(self, key[1:], value, True)\n",
    "            if new_remainder.key > new_root.key:\n",
    "                new_root.right = new_remainder\n",
    "            else:\n",
    "                new_root.left = new_remainder\n",
    "            \n",
    "            print(\"Creating new root\")\n",
    "            self.roots.append(new_root)\n",
    "                \n",
    "            \n",
    "        \n",
    "rt = RadixTree(None, None)\n",
    "rt.insert(\"hello\", \"hi\")\n",
    "print(rt.roots[0].key)\n",
    "assert rt.roots[0].key == \"h\"\n",
    "print(rt.roots[0].left.key)\n",
    "assert rt.roots[0].left.key == \"ello\"\n",
    "rt.insert(\"hup\", \"hi\")\n",
    "print(len(rt.roots))\n",
    "assert rt.roots[0].right.key == \"up\"\n",
    "\n",
    "split = rt.insert(\"helicopter\", \"world\")\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "assert rt.roots[0].left.key == \"el\"\n",
    "\n",
    "print(rt.roots[0].left.key)\n",
    "print(rt.roots[0].left.left.key)\n",
    "print(\"[\" + rt.roots[0].left.right.key +\"]yes\")\n",
    "assert rt.roots[0].left.right.key == \"lo\"\n",
    "\n",
    "print(rt.roots[0].left.left.key)\n",
    "assert rt.roots[0].left.left.key == \"icopter\"\n",
    "rt.insert(\"helicopterish\", \"none\")\n",
    "\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "assert rt.roots[0].left.left.right.key == \"ish\"\n",
    "\n",
    "rt.insert(\"hupello\", \"hi\")\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "assert rt.roots[0].right.left.key == \"ello\"\n",
    "\n",
    "rt.insert(\"hupellorella\", \"hi\")\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "assert rt.roots[0].right.left.right.key == \"rella\"\n",
    "\n",
    "rt.insert(\"samuel\", \"hi\")\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "\n",
    "rt.insert(\"samuelella\", \"hi\")\n",
    "\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "\n",
    "rt.insert(\"samuelellaella\", \"hi\")\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "\n",
    "rt.insert(\"samuelellaellabella\", \"hi\")\n",
    "print(\"walking\")\n",
    "for node in rt.roots[0].walk():\n",
    "    print(node)\n",
    "print(\"walked\")\n",
    "\n",
    "for item in rt.roots[1].prefixed(\"s\"):\n",
    "    print(item)\n",
    "\n",
    "rt.roots[0].validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"icopter\" < \"el\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"el\" > \"h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"rella\" > \"ello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ello\" < \"hup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"lo\" > \"hel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadixNode():\n",
    "    def __init__(self, key, left, right):\n",
    "        self.key = key\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "    def walk(self):\n",
    "        \n",
    "        if self.left:\n",
    "            yield from self.left.walk()\n",
    "        yield self\n",
    "        if self.right:\n",
    "            yield from self.right.walk()\n",
    "    \n",
    "    def verify(self):\n",
    "        i = list(reversed(list(self.walk())))\n",
    "        previous_node_key = i[0]\n",
    "        print(previous_node_key.key)\n",
    "        for node in i[1:]:\n",
    "            print(node.key)\n",
    "            if node.key > previous_node_key.key:\n",
    "                previous_node_key = node.key\n",
    "                continue\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "root = RadixNode(\"r\",\n",
    "                 RadixNode(\"om\",\n",
    "                           RadixNode(\"ulus\", None, None),\n",
    "                           RadixNode(\"an\",\n",
    "                                     RadixNode(\"e\", None, None),\n",
    "                                     RadixNode(\"us\", None, None))),\n",
    "                 RadixNode(\"ub\",\n",
    "                           RadixNode(\"e\",\n",
    "                                     RadixNode(\"ns\", None, None),\n",
    "                                     RadixNode(\"r\", None, None)),\n",
    "                          RadixNode(\"ic\", RadixNode(\"on\", None, None),\n",
    "                                   RadixNode(\"undus\", None, None))))\n",
    "root.verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ulus\" < \"om\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"om\" < \"r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_substring(value1, value2):\n",
    "    i = 0\n",
    "    while i < len(value1) and i < len(value2):\n",
    "        if value1[i] == value2[i]:\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    return (value1[0:i], i)\n",
    "\n",
    "class NewRadix:\n",
    "    def __init__(self, prefix, children, value=None):\n",
    "        self.prefix = prefix\n",
    "        self.children = children\n",
    "        self.value = value \n",
    "    \n",
    "    def child_prefixes(self, prefix):\n",
    "        for child in self.children:\n",
    "            yield child\n",
    "            if child.prefix.startswith(prefix):\n",
    "                \n",
    "                yield from child.child_prefixes(prefix)\n",
    "\n",
    "        \n",
    "    \n",
    "    def prefixes(self, prefix):\n",
    "        for child in self.children:\n",
    "            if child.prefix == prefix:\n",
    "                yield child\n",
    "            if prefix.startswith(child.prefix):\n",
    "                yield from child.child_prefixes(prefix)\n",
    "        \n",
    "\n",
    "    \n",
    "    def highest_prefix(self, prefix):\n",
    "        highest = None\n",
    "        common = None\n",
    "        for child in self.children:\n",
    "            if prefix.startswith(child.prefix):\n",
    "                new_common = common_substring(prefix, child.prefix)\n",
    "                if highest == None:\n",
    "                    highest = child\n",
    "                    common = new_common\n",
    "                test, new_common = child.highest_prefix(prefix)\n",
    "                if highest == None:\n",
    "                    highest = test\n",
    "                if test:\n",
    "                    if len(test.prefix) > len(highest.prefix):\n",
    "                        highest = test\n",
    "                        common = new_common\n",
    "        return highest, common\n",
    "    \n",
    "    def insert(self, prefix, value=None):\n",
    "        # find the longest match where we belong\n",
    "        highest_prefix, common = self.highest_prefix(prefix)\n",
    "        if highest_prefix != None:\n",
    "            common_substring, length = common\n",
    "            new_item = NewRadix(prefix, value=value, children=[])\n",
    "            highest_prefix.children.append(new_item)\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            new_remainder = NewRadix(prefix, value=value, children=[])\n",
    "            new_item = NewRadix(prefix[:1], value=None, children=[new_remainder])\n",
    "            self.children.append(new_item)\n",
    "            \n",
    "        \n",
    "        \n",
    "root = NewRadix(\"\", children=[NewRadix(\"h\", children=[NewRadix(\"hello\", children=[])])])\n",
    "\n",
    "root.insert(\"hellohello\", None)\n",
    "\n",
    "items = list(root.prefixes(\"h\"))\n",
    "for item in items:\n",
    "    print(\"h match\")\n",
    "    print(item.prefix)\n",
    "    \n",
    "root.insert(\"bumf\", None)\n",
    "\n",
    "\n",
    "items = list(root.prefixes(\"bumf\"))\n",
    "for item in items:\n",
    "    print(\"bumf match\")\n",
    "    print(item.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openbracket\n",
      "start\n",
      "nexttoken separator\n",
      "separator\n",
      "Person\n",
      "closebracket\n",
      "parsed a label dash\n",
      "leftordash dash\n",
      "squareopen\n",
      "FRIEND\n",
      "rightarrow\n",
      "openbracket\n",
      "end\n",
      "nexttoken separator\n",
      "separator\n",
      "Person\n",
      "closebracket\n",
      "parsed a label return\n",
      "[{'kind': 'match', 'variable': 'start', 'label': 'Person', 'attributes': {}}, {'kind': 'relationship', 'name': 'FRIEND'}, {'kind': 'match', 'variable': 'end', 'label': 'Person', 'attributes': {}}]\n",
      "['start', 'end']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class CypherParser():\n",
    "    def __init__(self):\n",
    "        self.last_char = \" \"\n",
    "        self.pos = 0\n",
    "        self.end = False\n",
    "        self.graph = []\n",
    "        self.return_clause = []\n",
    "   \n",
    "\n",
    "    def getchar(self):\n",
    "        \n",
    "        char = self.statement[self.pos]\n",
    "        if self.pos + 1 == len(self.statement):\n",
    "            self.end = True\n",
    "            return char\n",
    "        self.pos = self.pos + 1\n",
    "        \n",
    "        return char\n",
    "        \n",
    "    def gettok(self):\n",
    "        while (self.end == False and (self.last_char == \" \" or self.last_char == \"\\n\")):\n",
    "            self.last_char = self.getchar()\n",
    "        \n",
    "        \n",
    "              \n",
    "        if self.last_char == \"(\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"openbracket\"\n",
    "        \n",
    "        if self.last_char == \")\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"closebracket\"\n",
    "        \n",
    "        if self.last_char == \"*\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"wildcard\"\n",
    "        \n",
    "        if self.last_char == \"'\":\n",
    "            self.last_char = self.getchar()\n",
    "            identifier = \"\"\n",
    "            while self.end == False and self.last_char != \"'\":\n",
    "                if self.last_char == \"\\\\\":\n",
    "                    self.last_char = self.getchar()\n",
    "                identifier = identifier + self.last_char\n",
    "                self.last_char = self.getchar()\n",
    "            if self.end and self.last_char != \")\" and self.last_char != \"'\":\n",
    "                identifier += self.last_char\n",
    "            \n",
    "            self.last_char = self.getchar()\n",
    "            \n",
    "            return identifier\n",
    "        \n",
    "        if re.match(\"[a-zA-Z0-9\\.\\_]+\", self.last_char):\n",
    "            identifier = \"\"\n",
    "            while self.end == False and re.match(\"[a-zA-Z0-9\\.\\_]+\", self.last_char):\n",
    "                \n",
    "                identifier = identifier + self.last_char\n",
    "                self.last_char = self.getchar()\n",
    "            \n",
    "            if self.end and self.last_char != \")\":\n",
    "                identifier += self.last_char\n",
    "            \n",
    "            return identifier\n",
    "    \n",
    "        if self.last_char == \"=\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"eq\"\n",
    "        \n",
    "        if self.last_char == \"~\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"tilde\"\n",
    "        \n",
    "        if self.last_char == \",\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"comma\"\n",
    "        \n",
    "        if self.last_char == \":\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"separator\"\n",
    "        \n",
    "        if self.last_char == \"{\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"opencurly\"\n",
    "        \n",
    "        if self.last_char == \"}\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"closecurly\"\n",
    "        \n",
    "        if self.last_char == \"<\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"leftarrow\"\n",
    "        \n",
    "        if self.last_char == \">\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"rightarrow\"\n",
    "        \n",
    "        if self.last_char == \"-\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"dash\"\n",
    "        \n",
    "        if self.last_char == \"[\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"squareopen\"\n",
    "        \n",
    "        if self.last_char == \"]\":\n",
    "            self.last_char = self.getchar()\n",
    "            return \"squareclose\"\n",
    "        \n",
    "        if self.end:\n",
    "            return None\n",
    "# MATCH (wallstreet:Movie {title: 'Wall Street'})<-[:ACTED_IN]-(actor)\n",
    "# RETURN actor.name\n",
    "    def parse(self, statement):\n",
    "        self.statement = statement\n",
    "        token = self.gettok()\n",
    "        if token == \"match\":\n",
    "            self.parse_match()\n",
    "    \n",
    "    def parse_attribute(self):\n",
    "        attribute_name = self.gettok()\n",
    "        separator = self.gettok()\n",
    "        attribute_value = self.gettok()\n",
    "        \n",
    "        self.graph[-1][\"attributes\"][attribute_name] = attribute_value\n",
    "        print(\"New attribute: {} = {}\".format(attribute_name, attribute_value))\n",
    "        \n",
    "        token = self.gettok()\n",
    "        if token == \"comma\":\n",
    "            self.parse_attribute()\n",
    "    \n",
    "    def parse_relationship(self, token):\n",
    "        arrow_at_end = False\n",
    "        if token == \"dash\":\n",
    "            arrow_at_end = True\n",
    "        if token == \"leftarrow\":\n",
    "            dash = self.gettok()\n",
    "            print(\"dash \" + dash)\n",
    "        \n",
    "        openbracket = self.gettok()\n",
    "        print(openbracket)\n",
    "        separator = self.gettok()\n",
    "        relationship_name = self.gettok()\n",
    "        print(relationship_name)\n",
    "        closebracket = self.gettok()\n",
    "        dash = self.gettok()\n",
    "        if arrow_at_end:\n",
    "            rightarrow = self.gettok()\n",
    "            print(rightarrow)\n",
    "        self.graph.append({\n",
    "            \"kind\": \"relationship\",\n",
    "            \"name\": relationship_name\n",
    "        })\n",
    "        \n",
    "        self.parse_match()\n",
    "    \n",
    "    def parse_return(self):\n",
    "        variable = self.gettok()\n",
    "        self.return_clause.append(variable)\n",
    "        token = self.gettok()\n",
    "        if token == \"comma\":\n",
    "            self.parse_return()\n",
    "    \n",
    "    def parse_remainder(self, token):\n",
    "        \n",
    "        if token == \"return\":\n",
    "            self.parse_return()\n",
    "    \n",
    "    def parse_relationship_begin(self, token):\n",
    "        print(\"leftordash \" + token)\n",
    "        if token == \"leftarrow\" or token == \"dash\":\n",
    "            self.parse_relationship(token)\n",
    "        if token == \"comma\":\n",
    "            self.parse_match()\n",
    "\n",
    "    def parse_match(self):\n",
    "        token = self.gettok()\n",
    "        print(token)\n",
    "        if token == \"openbracket\":\n",
    "            variable = self.gettok()\n",
    "            print(variable)\n",
    "            token = self.gettok()\n",
    "            print(\"nexttoken \" + token)\n",
    "            self.graph.append({\n",
    "                \"kind\": \"match\",\n",
    "                \"variable\": variable\n",
    "            })\n",
    "            \n",
    "            if token == \"separator\":\n",
    "                # we have a label\n",
    "                print(token)\n",
    "                label = self.gettok()\n",
    "\n",
    "                self.graph[-1][\"label\"] = label\n",
    "                self.graph[-1][\"attributes\"] = {}\n",
    "\n",
    "                print(label)\n",
    "                token = self.gettok()\n",
    "                print(token)\n",
    "                if token == \"opencurly\": # begin attributes\n",
    "\n",
    "                    self.parse_attribute()\n",
    "                    print(\"begin attributes \" + token)\n",
    "                    closebracket = self.gettok()\n",
    "            \n",
    "                token = self.gettok()\n",
    "                print(\"parsed a label \" + token)\n",
    "                if token == \"return\":\n",
    "                    self.parse_remainder(token)\n",
    "                else:\n",
    "                    self.parse_relationship_begin(token)\n",
    "            \n",
    "            if token == \"closebracket\":\n",
    "                token = self.gettok()\n",
    "                print(\"innertoken \" + token)\n",
    "                if token == \"comma\":\n",
    "                    self.parse_match()\n",
    "                elif token == \"dash\" or token == \"leftarrow\":\n",
    "                    self.parse_relationship_begin(token)\n",
    "                else:\n",
    "                    self.parse_remainder(token)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "parser = CypherParser()\n",
    "# parser.parse(\"match (start:Person)-[:FRIEND]->(end:Person), (start)-[:LIKES]->(post:Post)<-[:POSTED]-(end) return start, end\")\n",
    "# match (start:Person)-[:FRIEND]->(end:Person) return start, end\n",
    "parser.parse(\"match (start:Person)-[:FRIEND]->(end:Person) return start, end\")\n",
    "print(parser.graph)\n",
    "print(parser.return_clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing data 1 1\n",
      "Resizing data 1 1\n",
      "Resizing data 1 1\n",
      "Resizing data 2 2\n",
      "Resizing data 2 2\n",
      "Resizing data 2 2\n",
      "Resizing data 3 3\n",
      "Resizing data 3 3\n",
      "Resizing data 3 3\n",
      "Resizing data 4 4\n",
      "Resizing data 4 4\n",
      "Resizing data 4 4\n",
      "Resizing data 5 5\n",
      "Resizing data 5 5\n",
      "Resizing data 5 5\n",
      "Resizing data 6 6\n",
      "Resizing data 6 6\n",
      "Resizing data 6 6\n",
      "Resizing data 7 7\n",
      "Resizing data 7 7\n",
      "Resizing data 7 7\n",
      "Resizing data 8 8\n",
      "Resizing data 8 8\n",
      "Resizing data 8 8\n",
      "Resizing data 9 9\n",
      "Resizing data 9 9\n",
      "Resizing data 9 9\n",
      "Samuel (1) -> Tasya (2)\n",
      "1_2\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Tasya (2) -> Samuel (1)\n",
      "2_1\n",
      "Samuel (1) -> Simon (0)\n",
      "1_0\n",
      "Simon (0) -> Samuel (1)\n",
      "0_1\n",
      "Samuel (1) -> John (3)\n",
      "1_3\n",
      "Simon (0) -> Sally (4)\n",
      "0_4\n",
      "Sally (4) -> Simon (0)\n",
      "4_0\n",
      "Tasya (2) -> Margaret (5)\n",
      "2_5\n",
      "Margaret (5) -> Tasya (2)\n",
      "5_2\n",
      "array([[0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Samuel (1) -> Ideas (6)\n",
      "1_6\n",
      "Tasya (2) -> Ideas (6)\n",
      "2_6\n",
      "Tasya (2) -> Thoughts (7)\n",
      "2_7\n",
      "Tasya (2) -> Lamentations (8)\n",
      "2_8\n",
      "Samuel (1) -> Thoughts (7)\n",
      "1_7\n",
      "openbracket\n",
      "start\n",
      "nexttoken separator\n",
      "separator\n",
      "Person\n",
      "opencurly\n",
      "New attribute: name = Samuel\n",
      "begin attributes opencurly\n",
      "parsed a label dash\n",
      "leftordash dash\n",
      "squareopen\n",
      "FRIEND\n",
      "rightarrow\n",
      "openbracket\n",
      "end\n",
      "nexttoken separator\n",
      "separator\n",
      "Person\n",
      "closebracket\n",
      "parsed a label return\n",
      "[{'attributes': {'name': 'Samuel'},\n",
      "  'kind': 'match',\n",
      "  'label': 'Person',\n",
      "  'variable': 'start'},\n",
      " {'kind': 'relationship', 'name': 'FRIEND'},\n",
      " {'attributes': {}, 'kind': 'match', 'label': 'Person', 'variable': 'end'}]\n",
      "1\n",
      "We in first match\n",
      "[{'attributes': {'label': 'Person', 'name': 'Samuel'},\n",
      "  'name': 'Samuel',\n",
      "  'position': 1}]\n",
      "Adding Samuel\n",
      "{'attributes': {'name': 'Samuel'},\n",
      " 'kind': 'match',\n",
      " 'label': 'Person',\n",
      " 'variable': 'start'}\n",
      "Found variable False\n",
      "Now searching FRIEND\n",
      "Samuel -FRIEND-> Simon\n",
      "Samuel -FRIEND-> Tasya\n",
      "Samuel -FRIEND-> John\n",
      "2\n",
      "Length after pop 1\n",
      "'Marking as filled end'\n",
      "'start'\n",
      "We're merging\n",
      "{'attributes': {}, 'kind': 'match', 'label': 'Person', 'variable': 'end'}\n",
      "Saving Person to start\n",
      "Saving Person to start\n",
      "Saving Person to start\n",
      "[{'attributes': {'name': 'Samuel'},\n",
      "  'kind': 'match',\n",
      "  'label': 'Person',\n",
      "  'variable': 'start'},\n",
      " {'kind': 'relationship', 'name': 'FRIEND'},\n",
      " {'attributes': {}, 'kind': 'match', 'label': 'Person', 'variable': 'end'}]\n",
      "[{'count': 1,\n",
      "  'id': 1,\n",
      "  'matches': [{'from_node': {'attributes': {'label': 'Person',\n",
      "                                            'name': 'Samuel'},\n",
      "                             'name': 'Samuel',\n",
      "                             'position': 1,\n",
      "                             'start': True},\n",
      "               'planning_index': 2,\n",
      "               'relationship': 'FRIEND',\n",
      "               'to_node': {'attributes': {'label': 'Person', 'name': 'Simon'},\n",
      "                           'end': True,\n",
      "                           'name': 'Simon',\n",
      "                           'position': 0}},\n",
      "              {'from_node': {'attributes': {'label': 'Person',\n",
      "                                            'name': 'Samuel'},\n",
      "                             'name': 'Samuel',\n",
      "                             'position': 1,\n",
      "                             'start': True},\n",
      "               'planning_index': 2,\n",
      "               'relationship': 'FRIEND',\n",
      "               'to_node': {'attributes': {'label': 'Person', 'name': 'Tasya'},\n",
      "                           'end': True,\n",
      "                           'name': 'Tasya',\n",
      "                           'position': 2}},\n",
      "              {'from_node': {'attributes': {'label': 'Person',\n",
      "                                            'name': 'Samuel'},\n",
      "                             'name': 'Samuel',\n",
      "                             'position': 1,\n",
      "                             'start': True},\n",
      "               'planning_index': 2,\n",
      "               'relationship': 'FRIEND',\n",
      "               'to_node': {'attributes': {'label': 'Person', 'name': 'John'},\n",
      "                           'end': True,\n",
      "                           'name': 'John',\n",
      "                           'position': 3}}],\n",
      "  'old_matches': [[{'planning_index': 0,\n",
      "                    'to_node': {'attributes': {'label': 'Person',\n",
      "                                               'name': 'Samuel'},\n",
      "                                'name': 'Samuel',\n",
      "                                'position': 1,\n",
      "                                'start': True}}]]}]\n",
      "Return clauses\n",
      "['start', 'end']\n",
      "{'end': [{'attributes': {'label': 'Person', 'name': 'Simon'},\n",
      "          'end': True,\n",
      "          'name': 'Simon',\n",
      "          'position': 0},\n",
      "         {'attributes': {'label': 'Person', 'name': 'Tasya'},\n",
      "          'end': True,\n",
      "          'name': 'Tasya',\n",
      "          'position': 2},\n",
      "         {'attributes': {'label': 'Person', 'name': 'John'},\n",
      "          'end': True,\n",
      "          'name': 'John',\n",
      "          'position': 3}],\n",
      " 'start': [{'attributes': {'label': 'Person', 'name': 'Samuel'},\n",
      "            'name': 'Samuel',\n",
      "            'position': 1,\n",
      "            'start': True},\n",
      "           {'attributes': {'label': 'Person', 'name': 'Samuel'},\n",
      "            'name': 'Samuel',\n",
      "            'position': 1,\n",
      "            'start': True},\n",
      "           {'attributes': {'label': 'Person', 'name': 'Samuel'},\n",
      "            'name': 'Samuel',\n",
      "            'position': 1,\n",
      "            'start': True}]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        self.data = {}\n",
    "        self.index = {}\n",
    "        self.relationships = {}\n",
    "        self.directions = defaultdict(dict)\n",
    "        self.attribute_index = {}\n",
    "        \n",
    "    def add_relationship(self, name):\n",
    "        self.data[name] = np.empty((0, 0))\n",
    "        self.data[name].fill(0)\n",
    "\n",
    "    def index_attributes(self, position, attributes):\n",
    "        for key, value in attributes.items():\n",
    "            lookup_string = \"{}={}\".format(key, value)\n",
    "            if lookup_string in self.attribute_index:\n",
    "                self.attribute_index[lookup_string].append(position)\n",
    "            else:\n",
    "                self.attribute_index[lookup_string] = [position]\n",
    "        \n",
    "    def add_node(self, name, attributes):\n",
    "        position = len(self.nodes)\n",
    "        attributes[\"name\"] = name\n",
    "        data = {\"position\": position, \"name\": name, \"attributes\": attributes}\n",
    "        self.index[name] = data\n",
    "        \n",
    "        self.index_attributes(position, attributes)\n",
    "        \n",
    "        self.nodes.append(data)\n",
    "        size = position + 1\n",
    "        for relationship, relationship_data in self.data.items():\n",
    "            print(\"Resizing data {} {}\".format(size, size))\n",
    "            self.data[relationship] = np.resize(relationship_data, (size, size))\n",
    "    \n",
    "    def add_edge(self, _from, to, relationship):\n",
    "        from_node = self.index[_from]\n",
    "        to_node = self.index[to]\n",
    "        print(\"{} ({}) -> {} ({})\".format(\n",
    "            from_node[\"name\"], from_node[\"position\"], to_node[\"name\"], to_node[\"position\"]))\n",
    "        \n",
    "        self.data[relationship][from_node[\"position\"]][to_node[\"position\"]] = 1\n",
    "        self.data[relationship][to_node[\"position\"]][from_node[\"position\"]] = 1\n",
    "        \n",
    "        direction_index = \"{}_{}\".format(from_node[\"position\"], to_node[\"position\"])\n",
    "        print(direction_index)                            \n",
    "        self.directions[relationship][direction_index] = True\n",
    "        if to == \"Tasya\":\n",
    "            pprint(self.data[relationship])\n",
    "        # self.relationships[\"{}_{}\".format(from_node[\"position\"], to_node[\"position\"])] = attributes\n",
    "        \n",
    "        \n",
    "    \n",
    "    def edges_from(self, relationship, node):\n",
    "        multiply = np.empty((self.data[relationship].shape[0], self.data[relationship].shape[1]))\n",
    "        print(\"Multiply matrix\")\n",
    "        multiply.fill(0)\n",
    "        for item in range(0, self.data[relationship].shape[1]):\n",
    "            multiply[self.index[node][\"position\"], item] = 1\n",
    "            # multiply[item, self.index[node][\"position\"]] = 1\n",
    "        pprint(multiply)\n",
    "        print(\"Result matrix\")\n",
    "        edges_from = np.matmul(self.data[relationship], multiply)\n",
    "        pprint(edges_from)\n",
    "        for item in range(0, edges_from.shape[1]):\n",
    "            print(\"{}? {}\".format(self.nodes[item][\"name\"], edges_from[item, item]))\n",
    "        print(\"Edges from them them onwards\")\n",
    "        from_them = np.matmul(self.data[relationship], edges_from)\n",
    "        print(\"From them\")\n",
    "        pprint(from_them)\n",
    "        for item in range(0, from_them.shape[1]):\n",
    "            print(\"{}? {}\".format(self.nodes[item][\"name\"], from_them[item, item]))\n",
    "    \n",
    "    def find_nodes_from_attributes(self, attributes):\n",
    "        matches = set()\n",
    "        for key, value in attributes.items():\n",
    "            lookup_string = \"{}={}\".format(key, value)\n",
    "            if lookup_string in self.attribute_index:\n",
    "                for node in self.attribute_index[lookup_string]:\n",
    "                    \n",
    "                    matches.add(node)\n",
    "        for item in matches:\n",
    "            yield self.nodes[item]\n",
    "    \n",
    "    def find_nodes_by_label(self, label):\n",
    "        return self.find_nodes_from_attributes({\"label\": label})\n",
    "    \n",
    "    def create_matrix(self, adjacency_matrix, nodes):\n",
    "        multiply = np.empty((adjacency_matrix.shape[0], adjacency_matrix.shape[1]))\n",
    "        multiply.fill(0)\n",
    "        for node in nodes:\n",
    "            for item in range(0, adjacency_matrix.shape[1]):\n",
    "                multiply[node[\"position\"]][item] = 1\n",
    "        return multiply\n",
    "    \n",
    "    def query(self, cypher):\n",
    "        count = 0\n",
    "        parser = CypherParser()\n",
    "        parser.parse(cypher)\n",
    "        pprint(parser.graph)\n",
    "        nodes_to_iterate = []\n",
    "        first_match = parser.graph[0]\n",
    "        \n",
    "        matching_stack = []\n",
    "        matching_nodes = []\n",
    "        relationships = []\n",
    "        variables = {}\n",
    "        for planning_index, planning_node in enumerate(parser.graph):\n",
    "            if planning_node[\"kind\"] == \"match\":\n",
    "                \n",
    "                matching_stack.append(planning_node)\n",
    "                pprint(len(matching_stack))\n",
    "                if len(matching_stack) == 1:\n",
    "                    print(\"We in first match\")\n",
    "                    \n",
    "                    matching_nodes = []\n",
    "                    \n",
    "                    if relationships:\n",
    "                        # we have context to begin with\n",
    "                        print(\"We're continuing from the beginning context\")\n",
    "                        \n",
    "                        seen_before = planning_node[\"variable\"] in variables\n",
    "                        print(seen_before)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    elif \"attributes\" in planning_node and planning_node[\"attributes\"]:\n",
    "                        # we need to find a source node based on attributes\n",
    "                        matching_nodes = list(self.find_nodes_from_attributes(planning_node[\"attributes\"]))\n",
    "                        pprint(matching_nodes)\n",
    "                    elif \"label\" in planning_node:\n",
    "                        matching_nodes = self.find_nodes_by_label(planning_node[\"label\"])\n",
    "                        print(\"Found matching nodes\")\n",
    "                        \n",
    "                    else:\n",
    "                        print(\"We're starting with all nodes firstly\")\n",
    "                        matching_nodes = self.nodes\n",
    "                    \n",
    "                    if matching_nodes:\n",
    "                    \n",
    "                        def enrich_variable(nodes):\n",
    "                            variable_name = planning_node[\"variable\"]\n",
    "                            for matching_node in nodes:\n",
    "                                copy = matching_node.copy()\n",
    "                                copy[variable_name] = True\n",
    "                                yield copy\n",
    "\n",
    "\n",
    "                        if \"variable\" in planning_node:\n",
    "                            matching_nodes = enrich_variable(matching_nodes)\n",
    "\n",
    "                        # relationships.clear()\n",
    "                        # create initial relationships\n",
    "\n",
    "                        count = 0\n",
    "                        for matching_node in matching_nodes:\n",
    "                            print(\"Adding {}\".format(matching_node[\"name\"]))\n",
    "                            matches = []\n",
    "                            count = count + 1\n",
    "                            relationships.append({\n",
    "                                \"id\": count,\n",
    "                                \"matches\": matches,\n",
    "                                \"old_matches\": [],\n",
    "                                \"count\": 0\n",
    "                                \n",
    "                            })\n",
    "                            matches.append({\n",
    "                                \"to_node\": matching_node,\n",
    "                                \"planning_index\": planning_index\n",
    "                            })\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    if \"variable\" in planning_node and planning_node[\"variable\"] not in variables:\n",
    "                        variables[planning_node[\"variable\"]] = {\n",
    "                            \"planning_index\": planning_index,\n",
    "                            \"relationships\": relationships,\n",
    "                            \"start_nodes\": matching_nodes,\n",
    "                            \"matching_nodes\": matching_nodes,\n",
    "                            \"usages\": 0,\n",
    "                            \"left_hand_variable\": True,\n",
    "                            \"filled\": False\n",
    "                        }\n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    seen_before = planning_node[\"variable\"] in variables\n",
    "                    \n",
    "                    if seen_before:\n",
    "                        # we have to do some merging of data\n",
    "                        print(\"{} has been seen before - we need to merge\".format(planning_node[\"variable\"]))\n",
    "                        needs_merge = True\n",
    "                        old_version = variables[planning_node[\"variable\"]][\"planning_index\"]\n",
    "                        for relationship in relationships:\n",
    "                            current_matches = relationship[\"matches\"]\n",
    "                            \n",
    "                            for match in relationship[\"old_matches\"][1:]:\n",
    "                                \n",
    "                                if match:\n",
    "                                    this_index = match[0][\"planning_index\"]\n",
    "                                    if this_index == old_version:\n",
    "                                        # we need to merge matches and relationship[\"matches\"]\n",
    "                                        print(\"We need to merge this data\")\n",
    "                                        \n",
    "                                        deletions = []\n",
    "                                        for current_match in current_matches:\n",
    "                                            from_node = current_match[\"to_node\"]\n",
    "                                            found = False\n",
    "                                            for node in match:\n",
    "                                                if node[\"to_node\"][\"name\"] == from_node[\"name\"]:\n",
    "                                                    found = True\n",
    "                                                    break\n",
    "                                            if not found:\n",
    "                                                deletions.append(current_match)\n",
    "                                        for deletion in deletions:\n",
    "                                            current_matches.remove(deletion)\n",
    "                                                \n",
    "                                            \n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                        \n",
    "                    \n",
    "                    # we're re-matching to end nodes\n",
    "                    # we don't need to keep track of the start anymore\n",
    "                    starting_nodes = matching_stack.pop(0)\n",
    "                    print(\"Length after pop {}\".format(len(matching_stack)))\n",
    "                    if \"variable\" in planning_node and planning_node[\"variable\"] not in variables:\n",
    "                        variable_name = planning_node[\"variable\"]\n",
    "                        \n",
    "                        variables[variable_name] = {\n",
    "                            \"relationships\": relationships,\n",
    "                            \"usages\": 0,\n",
    "                            \"left_hand_variable\": False,\n",
    "                            \"filled\": False\n",
    "                        }\n",
    "                    \n",
    "                    pprint(\"Marking as filled {}\".format(planning_node[\"variable\"]))\n",
    "                    variables[planning_node[\"variable\"]][\"filled\"] = True\n",
    "                    \n",
    "                    starting_nodes_variable = starting_nodes[\"variable\"]\n",
    "                    pprint(starting_nodes_variable)\n",
    "                    if \"variable\" in starting_nodes and starting_nodes_variable not in variables:\n",
    "                        variables[starting_nodes_variable] = {}\n",
    "                    \n",
    "                    \n",
    "                    right_matching_nodes = []\n",
    "                    print(\"We're merging\")\n",
    "                    pprint(planning_node)\n",
    "                    \n",
    "                    if \"label\" in planning_node:\n",
    "                        label = planning_node[\"label\"]\n",
    "                        \n",
    "                        rdeletions = []\n",
    "                        for relation in relationships:\n",
    "                            \n",
    "                            deletions = []\n",
    "                            for match in relation[\"matches\"]:\n",
    "                                if \"planning_index\" not in match:\n",
    "                                    match[\"planning_index\"] = planning_index\n",
    "                                if match[\"to_node\"][\"attributes\"][\"label\"] != label:\n",
    "\n",
    "                                    deletions.append(match)\n",
    "                                else:\n",
    "                                    print(\"Saving {} to {}\".format(label, variable))\n",
    "                                    right_matching_nodes.append(match[\"to_node\"])\n",
    "                        \n",
    "                            for deletion in deletions:\n",
    "                                pass  # relationship[\"matches\"].remove(deletion)\n",
    "                            if len(relation[\"matches\"]) == 0:\n",
    "                                # delete it\n",
    "                                # rdeletions.append(relation)\n",
    "                                pass\n",
    "                        for deletion in rdeletions:\n",
    "                            relationships.remove(deletion)\n",
    "                                \n",
    "                    else:\n",
    "                        for relationship in relationships:\n",
    "                            for match in relationship[\"matches\"]:\n",
    "                                right_matching_nodes.append(match[\"to_node\"])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if \"planning_index\" in variables[planning_node[\"variable\"]]:\n",
    "                        print(\"We need to rotate the relationships\")\n",
    "                        source_matches = variables[planning_node[\"variable\"]][\"planning_index\"]\n",
    "                        print(\"We need {}\".format(source_matches))\n",
    "                        \n",
    "                        for relationship in relationships:\n",
    "                            temporary_matches = None\n",
    "                            for old_matches in relationship[\"old_matches\"][1:]:\n",
    "                                if len(old_matches) > 0:\n",
    "                                    this_planning_index = old_matches[0][\"planning_index\"]\n",
    "                                    print(\"Found matches with planning index of {}\".format(this_planning_index))\n",
    "                                    if this_planning_index == source_matches:\n",
    "                                        temporary_matches = relationship[\"matches\"]\n",
    "                                        relationship[\"matches\"] = old_matches\n",
    "                                        relationship[\"rotated\"] = True\n",
    "                            \n",
    "                            if temporary_matches:\n",
    "                                relationship[\"old_matches\"].append(temporary_matches)\n",
    "                    \n",
    "                    \n",
    "                    variables[planning_node[\"variable\"]][\"planning_index\"] = planning_index \n",
    "                    \n",
    "                    if not seen_before:\n",
    "                        for matching_node in right_matching_nodes:\n",
    "                            matching_node[planning_node[\"variable\"]] = True\n",
    "                    \n",
    "                    matching_stack.pop()\n",
    "                        \n",
    "                 \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            if planning_node[\"kind\"] == \"relationship\":\n",
    "                \n",
    "                active_relationships = relationships\n",
    "                left_hand_variable = False\n",
    "                variable = None\n",
    "                variable_filled = False\n",
    "                if \"variable\" in matching_stack[-1]:\n",
    "                    pprint(matching_stack[-1])\n",
    "                    variable = matching_stack[-1][\"variable\"]\n",
    "                    left_hand_variable = variables[variable][\"left_hand_variable\"]                    \n",
    "                    variable_filled = variables[variable][\"filled\"]\n",
    "                    print(\"Found variable {}\".format(variable_filled))\n",
    "                    active_relationships = variables[variable][\"relationships\"]\n",
    "                    \n",
    "                \n",
    "                relationship_name = planning_node[\"name\"]\n",
    "                \n",
    "                print(\"Now searching {}\".format(relationship_name))\n",
    "                \n",
    "                \n",
    "                adjacency_matrix = self.data[relationship_name]\n",
    "                new_matching_nodes = []\n",
    "                \n",
    "                deletions = []\n",
    "                \n",
    "                \n",
    "                \n",
    "                for relationship in active_relationships:\n",
    "                    # if this relationship refers to left hand graph clause\n",
    "                    # ie match (person:Person)-[:FRIEND_OF]->(person2:Person)\n",
    "                    # person is a left hand variable because it starts the chain\n",
    "                    \n",
    "                    if left_hand_variable and relationship[\"count\"] == 1:\n",
    "                        matches = relationship[\"old_matches\"][0]\n",
    "                    elif variable and variable_filled:\n",
    "                        matching_index = variables[variable][\"planning_index\"]\n",
    "                        print(\"We're loading data from a past run {}\".format(matching_index))\n",
    "                        for match in relationship[\"old_matches\"]:\n",
    "                            if match:\n",
    "                                if match[0][\"planning_index\"] == matching_index:\n",
    "                                    # we need to use this data\n",
    "                                    print(\"Found data\")\n",
    "                                    matches = match\n",
    "                                    pprint(matches)\n",
    "                                    break\n",
    "                                    \n",
    "                    \n",
    "                    else:\n",
    "                        matches = relationship[\"matches\"]\n",
    "                        \n",
    "                    if relationship_name == \"POSTED\":\n",
    "                        pprint(matches)\n",
    "                    \n",
    "                    \n",
    "                    relationship[\"count\"] = relationship[\"count\"] + 1\n",
    "                    relationship[\"old_matches\"].append(relationship[\"matches\"])\n",
    "                    relationship[\"matches\"] = []\n",
    "                    \n",
    "                    for match in matches:\n",
    "                        node = match[\"to_node\"]\n",
    "                        multiply_matrix = self.create_matrix(adjacency_matrix, [node])\n",
    "                        edges_from = np.matmul(adjacency_matrix, multiply_matrix)\n",
    "                        \n",
    "                        for item in range(0, edges_from.shape[1]):\n",
    "                           \n",
    "                            if edges_from[item][item] == 1:\n",
    "                                direction_index = \"{}_{}\".format(node[\"position\"], self.nodes[item][\"position\"])\n",
    "                                \n",
    "                                \n",
    "                                if self.directions[relationship_name].get(direction_index, False) == True:\n",
    "                                    print(\"{} -{}-> {}\".format(node[\"name\"], relationship_name, self.nodes[item][\"name\"]))    \n",
    "                                    \n",
    "                                    relationship[\"matches\"].append({\n",
    "                                        \"relationship\": relationship_name,\n",
    "                                        \"from_node\": node,\n",
    "                                        \"to_node\": self.nodes[item]\n",
    "                                    })\n",
    "                              \n",
    "                                    \n",
    "                                    new_matching_nodes.append(self.nodes[item])\n",
    "                                \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # update the variable\n",
    "                if \"variable\" in matching_stack[-1]:\n",
    "                    variables[matching_stack[-1][\"variable\"]][\"relationships\"] = active_relationships\n",
    "                relationships = active_relationships\n",
    "                \n",
    "        pprint(parser.graph)\n",
    "        pprint(relationships)\n",
    "        print(\"Return clauses\")\n",
    "        pprint(parser.return_clause)\n",
    "        for relation in relationships:\n",
    "            \n",
    "            output_row = {}\n",
    "            invalid_match = False\n",
    "            for return_clause in parser.return_clause:\n",
    "                if return_clause not in output_row:\n",
    "                        output_row[return_clause] = []\n",
    "                for matching in relation[\"matches\"]:\n",
    "                    \n",
    "                    if \"rotated\" not in relation:\n",
    "                        if matching[\"from_node\"].get(return_clause):\n",
    "                            output_row[return_clause].append(matching[\"from_node\"])\n",
    "                        elif matching[\"to_node\"].get(return_clause):\n",
    "                            output_row[return_clause].append(matching[\"to_node\"])\n",
    "\n",
    "                \n",
    "                    \n",
    "                for old_matches in reversed(relation[\"old_matches\"][1:]):\n",
    "                    found = False\n",
    "                    if not old_matches:\n",
    "                        invalid_match = True\n",
    "                    for old_match in old_matches:\n",
    "                        if old_match[\"from_node\"].get(return_clause):\n",
    "\n",
    "                            output_row[return_clause].append(old_match[\"from_node\"])\n",
    "                            found = True\n",
    "\n",
    "                        elif old_match[\"to_node\"].get(return_clause):\n",
    "                            output_row[return_clause].append(old_match[\"to_node\"])\n",
    "                            found = True\n",
    "\n",
    "                    if found:\n",
    "                        break\n",
    "                        \n",
    "            if not invalid_match:\n",
    "                yield output_row\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "root = Graph()\n",
    "root.add_relationship(\"FRIEND\")\n",
    "root.add_relationship(\"LIKES\")\n",
    "root.add_relationship(\"POSTED\")\n",
    "root.add_node(\"Simon\", {\"label\": \"Person\"})\n",
    "root.add_node(\"Samuel\", {\"label\": \"Person\"})\n",
    "root.add_node(\"Tasya\", {\"label\": \"Person\"})\n",
    "root.add_node(\"John\", {\"label\": \"Person\"})\n",
    "root.add_node(\"Sally\", {\"label\": \"Person\"})\n",
    "root.add_node(\"Margaret\", {\"label\": \"Person\"})\n",
    "root.add_node(\"Ideas\", {\"label\": \"Post\"})\n",
    "root.add_node(\"Thoughts\", {\"label\": \"Post\"})\n",
    "root.add_node(\"Lamentations\", {\"label\": \"Post\"})\n",
    "\n",
    "root.add_edge(\"Samuel\", \"Tasya\", \"FRIEND\")\n",
    "root.add_edge(\"Tasya\", \"Samuel\", \"FRIEND\")\n",
    "root.add_edge(\"Samuel\", \"Simon\", \"FRIEND\")\n",
    "root.add_edge(\"Simon\", \"Samuel\", \"FRIEND\")\n",
    "root.add_edge(\"Samuel\", \"John\", \"FRIEND\")\n",
    "\n",
    "root.add_edge(\"Simon\", \"Sally\", \"FRIEND\")\n",
    "root.add_edge(\"Sally\", \"Simon\", \"FRIEND\")\n",
    "root.add_edge(\"Tasya\", \"Margaret\", \"FRIEND\")\n",
    "root.add_edge(\"Margaret\", \"Tasya\", \"FRIEND\")\n",
    "# root.edges_from(\"FRIEND\", \"Samuel\")\n",
    "\n",
    "\n",
    "\n",
    "root.add_edge(\"Samuel\", \"Ideas\", \"LIKES\")\n",
    "root.add_edge(\"Tasya\", \"Ideas\", \"POSTED\")\n",
    "root.add_edge(\"Tasya\", \"Thoughts\", \"POSTED\")\n",
    "root.add_edge(\"Tasya\", \"Lamentations\", \"POSTED\")\n",
    "root.add_edge(\"Samuel\", \"Thoughts\", \"LIKES\")\n",
    "\n",
    "\n",
    "matching = root.query(\"match (start:Person {'name': 'Samuel'})-[:FRIEND]->(end:Person) return start, end\")\n",
    "# matching = root.query(\"match (start:Person)-[:FRIEND]->(end:Person) return start, end\")\n",
    "#matching = root.query(\"match (start:Person {'name': 'Samuel'})-[:FRIEND]->(end:Person), (start)-[:LIKES]->(post:Post), (end)-[:POSTED]->(post) return start, end, post\")\n",
    "for item in matching:\n",
    "    pprint(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
